<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav ul li a { background-image: none; } </style> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>TensorFlow를 이용한 Deep Learning 02 | Rachel Docs</title> <meta name="generator" content="Jekyll v4.3.4" /> <meta property="og:title" content="TensorFlow를 이용한 Deep Learning 02" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="TensorFlow로 간단한 Linear Regression을 구현해보고자 한다." /> <meta property="og:description" content="TensorFlow로 간단한 Linear Regression을 구현해보고자 한다." /> <link rel="canonical" href="http://localhost:4000/dl/2025/01/01/TensorFlow%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-Deep-Learning-02.html" /> <meta property="og:url" content="http://localhost:4000/dl/2025/01/01/TensorFlow%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-Deep-Learning-02.html" /> <meta property="og:site_name" content="Rachel Docs" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2025-01-01T00:00:00+09:00" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="TensorFlow를 이용한 Deep Learning 02" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-01-01T00:00:00+09:00","datePublished":"2025-01-01T00:00:00+09:00","description":"TensorFlow로 간단한 Linear Regression을 구현해보고자 한다.","headline":"TensorFlow를 이용한 Deep Learning 02","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/dl/2025/01/01/TensorFlow%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-Deep-Learning-02.html"},"url":"http://localhost:4000/dl/2025/01/01/TensorFlow%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-Deep-Learning-02.html"}</script> <!-- End Jekyll SEO tag --> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> Rachel Docs </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Rachel Docs" aria-label="Search Rachel Docs" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://github.com/just-the-docs/just-the-docs-template" class="site-button" > Template Repository </a> </li> </ul> </nav> </div> <div class="main-content-wrap"> <div id="main-content" class="main-content"> <main> <h1>TensorFlow를 이용한 Deep Learning 02</h1> <p>TensorFlow로 간단한 Linear Regression을 구현해보고자 한다.</p> <p>TensorFlow의 기본인 3 가지 단계를 거치면서 구현이 될 것이다</p> <ol> <li>그래프를 build한다</li> <li>session을 run하면서 그래프를 실행시킨다</li> <li>실행 결과라 그래프를 업데이트하고 값을 반환해준다</li> </ol> <p>H(x) = Wx + b 꼴의 형태를 만들어보자.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_train</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">]</span>
</code></pre></div></div> <p>여기서 이 데이터들은 trainable한 데이터들이다. 즉, 텐서플로우가 실행되면서 자체적으로 변경될 수 있는 값이라는 것이다.</p> <p>텐서플로우를 실행시키기 전에 먼저 shape (unit, dim) 을 지정해준다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tf</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">()</span>

<span class="n">tf</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="c1"># units == output shape, input_dim == input shape
</span></code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">tf.keras.Sequential()</code> 은 순차적 신경망 모델을 정의하는 데 사용된다. 레이어를 순서대로 추가하면서, 입력 데이터가 처음부터 끝까지 한 방향으로만 처리되는 구조이다 (CNN 등에 사용될 수 있을 것). 대신 branching, parallel 연결이 필요한 복잡한 모델은 정의할 수 없다는 점이 한계점이다.</p> <p>이제 gradient descent를 위해 <code class="language-plaintext highlighter-rouge">tf.keras.optimizers.SGD</code>를 생성해서, 신경망 학습 과정에서 가중치를 업데이트하는 방식을 정의한다. 이를 통해 학습 속도 등의 하이퍼파라미터를 설정할 수 있다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sgd</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">tf</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sh">'</span><span class="s">mse</span><span class="sh">'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">sgd</span><span class="p">)</span>  
<span class="n">tf</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">summary</span><span class="p">()</span>
</code></pre></div></div> <p>여기서 SGD (Stochastic Gradient Descent ; 확률적 경사하강법)을 사용했다. 확률적인 이유는, 전체 데이터가 아니라 batch에 의해 선택된 소규모 데이터를 이용해서 가중치를 업데이트하기 때문이다. 계산 효율성도 높일 수 있고, 자꾸 지역 최적해로만 편중되지 않도록 만들어줄 수 있다.</p> <p><code class="language-plaintext highlighter-rouge">tf.model.compile()</code> 을 통해 옵티마이저를 모델에 설정한다.</p> <p><code class="language-plaintext highlighter-rouge">tf.model.summary()</code> 를 통해 결과를 확인해보면 다음과 같이 나왔다</p> <div class="table-wrapper"><table> <thead> <tr> <th>Layer (type)</th> <th>Output Shape</th> <th>Param #</th> </tr> </thead> <tbody> <tr> <td>dense (Dense)</td> <td>(None, 1)</td> <td>2</td> </tr> </tbody> </table></div> <p>그러면 모델도 준비되었으니 이제 진짜 학습을 해보자 !!!</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tf</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</code></pre></div></div> <p>Epoch 1/200</p> <p><strong>1/1</strong> ━━━━━━━━━━━━━━━━━━━━ <strong>0s</strong> 443ms/step - loss: 8.2096 Epoch 2/200</p> <p><strong>1/1</strong> ━━━━━━━━━━━━━━━━━━━━ <strong>0s</strong> 106ms/step - loss: 3.7242 Epoch 3/200</p> <p><strong>1/1</strong> ━━━━━━━━━━━━━━━━━━━━ <strong>0s</strong> 58ms/step - loss: 1.7081</p> <p>아주 잘 돌아가는 것을 볼 수 있다. 9초만에 끝난다 (이런 모델이 어디있담!!!!!)</p> <p>잘 학습이 되었다면 이 모델을 가지고 직접 예측값을 뽑아보자.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_predict</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]))</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y_predict</span><span class="p">)</span>
</code></pre></div></div> <p><strong>1/1</strong> ━━━━━━━━━━━━━━━━━━━━ <strong>0s</strong> 39ms/step [[-3.9989054] [-2.9994369]]</p> <p>바로 이렇게 배열로 도출되는 것을 볼 수 있다. 즉, 5에 대한 모델의 예측값은 -3.9989054, 4에 대한 모델의 예측값은 -2.9994369인 것 !</p> <p><a href="https://www.youtube.com/watch?v=mQGwjrStQgg&amp;list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm&amp;index=5">참고 유튜브 - hunkim</a></p><hr /> <h3> 🔗 Related Posts in DL </h3> <ul> <li><a href="/dl/2025/01/01/TensorFlow%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-Deep-Learning-04.html">TensorFlow를 이용한 Deep Learning 04</a> (2025-01-01)</li> <li><a href="/dl/2025/01/01/TensorFlow%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-Deep-Learning-03.html">TensorFlow를 이용한 Deep Learning 03</a> (2025-01-01)</li> <li><a href="/dl/2025/01/01/TensorFlow%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-Deep-Learning-01.html">TensorFlow를 이용한 Deep Learning 01</a> (2025-01-01)</li> </ul> <nav class="post-nav"> <a class="prev" href="/dl/2025/01/01/TensorFlow%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-Deep-Learning-01.html">← TensorFlow를 이용한 Deep Learning 01</a> <a class="next" href="/dl/2025/01/01/TensorFlow%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-Deep-Learning-03.html">TensorFlow를 이용한 Deep Learning 03 →</a> </nav> </main> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
