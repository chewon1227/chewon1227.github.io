<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav ul li a { background-image: none; } .site-nav > ul.nav-category-list > li > button svg { transform: rotate(-90deg); } .site-nav > ul.nav-category-list > li.nav-list-item > ul.nav-list { display: block; } </style> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>[GPT-1] Improving Language Understanding by Generative Pre-Training(2018) | Rachel Docs</title> <meta name="generator" content="Jekyll v4.3.4" /> <meta property="og:title" content="[GPT-1] Improving Language Understanding by Generative Pre-Training(2018)" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="chasing questions - psychology and ai" /> <meta property="og:description" content="chasing questions - psychology and ai" /> <link rel="canonical" href="http://localhost:4000/nlp/gpt1/" /> <meta property="og:url" content="http://localhost:4000/nlp/gpt1/" /> <meta property="og:site_name" content="Rachel Docs" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2025-04-15T00:00:00+09:00" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="[GPT-1] Improving Language Understanding by Generative Pre-Training(2018)" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-04-15T00:00:00+09:00","datePublished":"2025-04-15T00:00:00+09:00","description":"chasing questions - psychology and ai","headline":"[GPT-1] Improving Language Understanding by Generative Pre-Training(2018)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/nlp/gpt1/"},"url":"http://localhost:4000/nlp/gpt1/"}</script> <!-- End Jekyll SEO tag --> <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"> </script> <!-- KaTeX for math rendering --> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"> <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body, { delimiters: [ {left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false} ] });"> </script> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> Rachel Docs </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"> <li class="nav-list-item"> <a href="/" class="nav-list-link">Home</a> </li> <li class="nav-list-item"> <a href="/categories/dl.html" class="nav-list-link">DL</a> </li> <li class="nav-list-item"> <a href="/categories/nlp.html" class="nav-list-link">NLP</a> </li> <li class="nav-list-item"> <a href="/categories/eda.html" class="nav-list-link">EDA</a> </li> <li class="nav-list-item"> <a href="/categories/paper.html" class="nav-list-link">PAPER</a> </li> </ul> </nav> <nav aria-label="Categories" id="category-nav" class="site-nav"> <ul class="nav-list nav-category-list"> <li class="nav-list-item"> <button class="nav-list-expander btn-reset" aria-label="Toggle category DL" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <div class="nav-category">DL</div> <ul class="nav-list"> <li class="nav-list-item"> <a href="/dl/tensorflow-04/" class="nav-list-link"> TensorFlowë¥¼ ì´ìš©í•œ Deep Learning 04 </a> </li> <li class="nav-list-item"> <a href="/dl/tensorflow-03/" class="nav-list-link"> TensorFlowë¥¼ ì´ìš©í•œ Deep Learning 03 </a> </li> <li class="nav-list-item"> <a href="/dl/tensorflow-02/" class="nav-list-link"> TensorFlowë¥¼ ì´ìš©í•œ Deep Learning 02 </a> </li> <li class="nav-list-item"> <a href="/dl/tensorflow-01/" class="nav-list-link"> TensorFlowë¥¼ ì´ìš©í•œ Deep Learning 01 </a> </li> </ul> </li> </ul> <ul class="nav-list nav-category-list"> <li class="nav-list-item"> <button class="nav-list-expander btn-reset" aria-label="Toggle category EDA" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <div class="nav-category">EDA</div> <ul class="nav-list"> <li class="nav-list-item"> <a href="/eda/bus-eda-01/" class="nav-list-link"> ì„œìš¸ì‹œ ë²„ìŠ¤ ë…¸ì„  ì •ë¥˜ì¥ ìŠ¹í•˜ì°¨ ë¶„ì„ - 01 </a> </li> </ul> </li> </ul> <ul class="nav-list nav-category-list"> <li class="nav-list-item"> <button class="nav-list-expander btn-reset" aria-label="Toggle category NLP" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <div class="nav-category">NLP</div> <ul class="nav-list"> <li class="nav-list-item"> <a href="/nlp/react/" class="nav-list-link"> ReAct: Synergizing Reasoning and Acting in Language Models </a> </li> <li class="nav-list-item"> <a href="/nlp/gpt1/" class="nav-list-link"> [GPT-1] Improving Language Understanding by Generative Pre-Training(2018) </a> </li> <li class="nav-list-item"> <a href="/nlp/batchapi/" class="nav-list-link"> ì¼ë°˜ APIì™€ Batch API ì‚¬ìš©í•˜ê¸° </a> </li> <li class="nav-list-item"> <a href="/nlp/colab-finetune/" class="nav-list-link"> Colabìœ¼ë¡œ íŒŒì¸íŠœë‹(Fine-Tuning)í•˜ê¸° </a> </li> <li class="nav-list-item"> <a href="/nlp/colab-prompting/" class="nav-list-link"> Colabìœ¼ë¡œ í”„ë¡¬í”„íŒ…(Prompting)í•˜ê¸° </a> </li> </ul> </li> </ul> <ul class="nav-list nav-category-list"> <li class="nav-list-item"> <button class="nav-list-expander btn-reset" aria-label="Toggle category Paper" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <div class="nav-category">Paper</div> <ul class="nav-list"> <li class="nav-list-item"> <a href="/paper/2025/03/29/Attention.html" class="nav-list-link"> [Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015) </a> </li> <li class="nav-list-item"> <a href="/nlp/seq2seq/" class="nav-list-link"> Sequence-to-Sequence Models </a> </li> <li class="nav-list-item"> <a href="/paper/2025/02/24/LSTM.html" class="nav-list-link"> [LSTM] Long Short Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling (2014) </a> </li> <li class="nav-list-item"> <a href="/paper/2025/02/14/Word2Vec.html" class="nav-list-link"> [Word2Vec] Efficient Estimation of Word Representations in Vector Space (2013) </a> </li> <li class="nav-list-item"> <a href="/paper/2025/02/05/RNN.html" class="nav-list-link"> [RNN] Recurrent neural network based language model (2010) </a> </li> </ul> </li> </ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Rachel Docs" aria-label="Search Rachel Docs" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://github.com/just-the-docs/just-the-docs-template" class="site-button" > Template Repository </a> </li> </ul> </nav> </div> <div class="main-content-wrap"> <div id="main-content" class="main-content"> <main> <h1>[GPT-1] Improving Language Understanding by Generative Pre-Training(2018)</h1> <p><br /></p> <p><a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language Understanding by Generative Pre-Training</a></p> <p>íŠ¸ëœìŠ¤í¬ë¨¸ ë…¼ë¬¸ë³´ë‹¤ í›¨ì”¬ ì¹œì ˆí•˜ë‹¤.</p> <p><br /></p> <h2 id="1-intro"> <a href="#1-intro" class="anchor-heading" aria-labelledby="1-intro"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1. Intro </h2> <p>ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ë•Œ ê°€ì¥ ë§ì€ ì‹œê°„ì´ ì†Œìš”ë˜ëŠ” ê²ƒì€ ë°”ë¡œ data annotation, data curationì¸ ê²ƒ ê°™ë‹¤. ì‹¤ì œë¡œ ì•„ì£¼ ì •ì œê°€ ì˜ ë˜ì–´ ê°€ê³µí•  í•„ìš”ê°€ ê±°ì˜ ì—†ëŠ” ë°ì´í„°ë€ ì¡´ì¬í•˜ì§€ ì•Šê³ , ê°€ê³µë˜ì–´ìˆë‹¤ í•œë“¤ ì—°êµ¬ìë“¤ì´ ì‚¬ìš©í•˜ë ¤ê³  í•˜ëŠ” ë¼ë²¨ / ë¶„ë¥˜ì™€ ì •í™•íˆ ì¼ì¹˜í•  ìˆ˜ê°€ ì—†ê¸° ë•Œë¬¸ì´ë‹¤. ê°€ê³µë˜ì–´ ìˆì–´ë„ ì´ì •ë„ì¸ë°, ë³´í†µ ì—°êµ¬ì—ì„œ ì‚¬ìš©í•˜ë ¤ê³  í•˜ëŠ” real dataëŠ” ë¹„ê°€ê³µ ë°ì´í„°ë¡œ ì „í˜€ ì •ì œë˜ì–´ ìˆì§€ ì•Šê³ , í˜•ì‹ì¡°ì°¨ ì¤‘êµ¬ë‚œë°©ì´ë‹¤.</p> <p>ì´ ë…¼ë¬¸ì—ì„œë„ ì´ ë¶€ë¶„ì„ supervised NLPì—ì„œì˜ í•œê³„ì ìœ¼ë¡œ ì°ìœ¼ë©° ë…¼ì˜ë¥¼ ì‹œì‘í•˜ê³  ìˆë‹¤. labeled dataë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ê²°êµ­ annotationì´ í•„ìš”í•˜ë©°, ì´ë¥¼ í•˜ë‹¤ê°€ ëë‚œë‹¤ëŠ” ê²ƒì´ë‹¤.</p> <div class="callout"> ì•„ë‹ˆ ê·¸ëŸ¬ë©´ unlabeled dataë¡œ í•´ë³´ë©´ ë˜ëŠ”ê±° ì•„ë‹ˆì•¼? ê·¸ê²Œ ì–´ë ¤ìš´ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. - text representationì„ í•™ìŠµí•  ë•Œ ê°€ì¥ ì¢‹ì€ ê²ƒì´ ë­”ì§€ ë¶ˆí™•ì‹¤í•˜ë‹¤. - í•™ìŠµëœ í‘œí˜„ì„ target taskë¡œ ì—°ê²°ì‹œí‚¬ ë•Œ, í•©ì˜ëœ ê°€ì¥ íš¨ê³¼ì ì¸ ë°©ë²•ì´ ì—†ë‹¤. </div> <p>ê·¸ë˜ì„œ ì—¬ê¸°ì„  <code class="language-plaintext highlighter-rouge">semi-supervised approach</code> ë¥¼ ì œì‹œí•œë‹¤. ì¦‰, unsupervised pre-trainingê³¼ supervised fine-tuningì„ ê²°í•©í•˜ëŠ” ê²ƒì´ë‹¤. ê´‘ë²”ìœ„í•œ taskì— ìµœì†Œí•œì˜ adaptionì„ ê°€ì§€ê³ ë„ ì»¤ë²„í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ êµ¬í˜„í•˜ëŠ” ê²ƒì´ ìµœì¢…ì ì¸ ëª©ì ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤. ì´ë¥¼ ìœ„í•´ ë‘ ë‹¨ê³„ì˜ í•™ìŠµì„ ìˆ˜í–‰í•œë‹¤.</p> <ol> <li>unlabeld dataì— ëŒ€í•´ì„œ language modeling objectiveë¥¼ ì‚¬ìš©í•˜ì—¬ initial parameterë¥¼ í•™ìŠµí•¨</li> <li>ì´ë¥¼ target taskì— ì ìš©í•˜ê¸° ìœ„í•´ì„œ supervised learning</li> </ol> <p>ëª¨ë¸ì˜ êµ¬ì„± ìš”ì†Œë¡œëŠ” transformerì„ í™œìš©í•œë‹¤. transformerì€ attention êµ¬ì¡°ë¥¼ í™œìš©í•˜ê¸°ì— long-term textì™€ diverse taskì— transferí•  ë•Œ ê°•ë ¥í•˜ê¸° ë•Œë¬¸ì´ë‹¤. transferì„ í•  ë•Œ <code class="language-plaintext highlighter-rouge">traversal-style approaches</code> ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬, text inputì„ single contiguous sequence of tokenë“¤ë¡œ êµ¬ì¡°í™”í•˜ëŠ” ì‘ì—…ì„ ì§„í–‰í•œë‹¤. Pre-trainëœ ëª¨ë¸ì—ì„œ ë³€í˜•ì„ ìµœì†Œí™”í•˜ì—¬ íŒŒì¸íŠœë‹ì„ íš¨ê³¼ì ìœ¼ë¡œ ì§„í–‰í•  ìˆ˜ ìˆë‹¤.</p> <div class="callout"> Traversal-style approachê°€ ë­”ë°? taskê°€ ìì—°ì–´ë¡œ ì„¤ëª…ë˜ì–´ ì…ë ¥ë  ë•Œ ê·¸ ì…ë ¥ì„ í† í°ìœ¼ë¡œ êµ¬ë¶„í•˜ëŠ” ê²ƒ. ë³´í†µ start token, end token, delimiter ë“±ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤. </div> <p><br /></p> <h2 id="2-related-work"> <a href="#2-related-work" class="anchor-heading" aria-labelledby="2-related-work"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2. Related Work </h2> <h3 id="2-1-semi-supervised-learning-for-nlp"> <a href="#2-1-semi-supervised-learning-for-nlp" class="anchor-heading" aria-labelledby="2-1-semi-supervised-learning-for-nlp"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2-1. Semi-supervised Learning for NLP </h3> <p>ì´ˆê¸°ì—ëŠ” unlabeled dataë¥¼ ì´ìš©í•˜ì—¬ word-level / phrase-level ì„ ê³„ì‚°í•œ í›„ ì´ë¥¼ supervised modelì˜ íŠ¹ì„±ìœ¼ë¡œ ì´ìš©í•˜ì˜€ë‹¤. ê·¸ë¦¬ê³  ì‹¤ì œë¡œ ì—°êµ¬ìë“¤ì€ unlabeled coporaì—ì„œ í•™ìŠµëœ word embeddingì„ ì´ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•´ì™”ë‹¤. ê·¸ì¹˜ë§Œ, ì´ë“¤ì€ ê·¸ì € word-levelì—ì„œë§Œ ì‘ë™í•  ë¿, ìš°ë¦¬ê°€ ì£¼ëª©í•˜ê³ ì í•˜ëŠ” long-termê³¼ëŠ” ë§ì§€ ì•ŠëŠ”ë‹¤. ê·¸ë˜ì„œ ìµœê·¼ ì—°êµ¬ìë“¤ì€ unlabeled ë°ì´í„°ì—ì„œ word-level ì´ìƒì„ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì¸ì½”ë”©ì„ ëª©í‘œë¡œ ì—°êµ¬í•˜ê³  ìˆë‹¤.</p> <h3 id="2-2-unsupervised-pre-training"> <a href="#2-2-unsupervised-pre-training" class="anchor-heading" aria-labelledby="2-2-unsupervised-pre-training"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2-2. Unsupervised Pre-training </h3> <p>unsupervised pre-traininì€ good initialization pointë¥¼ ì¡ëŠ” ê²ƒì— ê°€ì¥ í° ì´ˆì ì„ ë‘ê³  ìˆë‹¤ (supervised learning objective ìˆ˜ì •í•˜ê¸° x). ê° taskì— ëŒ€í•´ ëª¨ë‘ ë§ì¶¤í˜•ìœ¼ë¡œ ì œì‘í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, í•˜ë‚˜ì˜ ëª¨ë¸ì´ ìµœì†Œí•œì˜ ë³€ê²½ë§Œ ê°€ì§€ê³  adaptí•  ìˆ˜ ìˆë„ë¡ í•˜ì—¬ íš¨ê³¼ì„±ì„ ê·¹ëŒ€í™”í•œë‹¤.</p> <p><br /></p> <h2 id="3-framework"> <a href="#3-framework" class="anchor-heading" aria-labelledby="3-framework"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3. Framework </h2> <h3 id="3-1-unsupervised-pre-training"> <a href="#3-1-unsupervised-pre-training" class="anchor-heading" aria-labelledby="3-1-unsupervised-pre-training"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3-1. Unsupervised Pre-training </h3> <p>Unlabeled ëœ token $ U = {u_1, â€¦, u_n} $ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, MLEë¥¼ ìœ„í•´</p> <p>$ L_1(U) = \sum_{i} \log P(u_i | u_{i-k}, â€¦, u_{i-1}; \Theta) \quad (1) $</p> <p>ë¥¼ ì‚¬ìš©í•œë‹¤.</p> <p>këŠ” context window sizeì´ê³ , PëŠ” conditional probabilityì´ë‹¤. ì¦‰, <strong>kê°œì˜ ë¬¸ë§¥ ë‹¨ìœ„ ì°½ë¬¸ìœ¼ë¡œ ê·¸ ë‹¤ìŒì— u_iê°€ ë‚˜ì˜¬ í™•ë¥ ì´ maximizeë˜ë„ë¡ \Theta ë¥¼ í•™ìŠµí•œë‹¤</strong> , ë¼ê³  ì´í•´í•˜ë©´ ë  ë“¯ í•˜ë‹¤. i ë²ˆì§¸ ë‹¨ì–´ë¥¼ ìœ„í•´ (i-k)ë²ˆì§¸ë¶€í„° (i-1)ë²ˆì§¸ ë‹¨ì–´ê¹Œì§€ë¥¼ ë³´ê³ , i ë²ˆì§¸ ë‹¨ì–´ê°€ ë‚˜ì˜¬ í™•ë¥ ì„ ìµœëŒ€í™”í•˜ë„ë¡ í•œë‹¤ëŠ” ê²ƒì´ë‹¤. MLEë¡œ ì ìš©ë˜ì–´ loss function ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•˜ê²Œ ë  ê²ƒì´ë‹¤. SGDë¥¼ í™œìš©í•˜ê¸°ì— back-propagationë„ ì§„í–‰í•œë‹¤.</p> <p>Language Modelë¡œëŠ” multi-layer Transformer decoderì„ ì´ìš©í•˜ì—¬ multi-headed self-attentionì„ ì§„í–‰í•œ í›„, position-wise feed-forward layerì„ í†µí•´ target tokenì— ëŒ€í•œ output distributionì„ ë§Œë“ ë‹¤. decoderë§Œ ì´ìš©í•œë‹¤ëŠ” ì ì´ íŠ¹ì§•ì´ë‹¤.</p> <p>$ h_0 = U W_e + W_p h_l = transformer*block(h*{l-1}) \quad \forall i \in [1, n] $</p> <p>$ P(u) = softmax(h_n W^T_e) \quad<br /> $</p> <p>$ U = (u_{-k}, â€¦, u_{-1}) $ ëŠ” í† í°ì˜ context vectorì€ layer ìˆ˜ì´ë‹¤. ì¦‰, context vector * token embedding + positional embeddingìœ¼ë¡œ h0ì„ ë§Œë“¤ì–´ì„œ transformer_blockì— ë„£ê³ , ê·¸ê±°ë‘ token embeddingì˜ ì „ì¹˜í–‰ë ¬ì„ ê³±í•œ ê²ƒ(ì ê³±)ì„ softmaxì— ë„£ì–´ì„œ í™•ë¥ ê°’ì„ êµ¬í•œë‹¤. ì´ë ‡ê²Œ output distributionì„ êµ¬í•œë‹¤ëŠ” ê²ƒì´ë‹¤.</p> <h3 id="3-2-supervised-fine-tuning"> <a href="#3-2-supervised-fine-tuning" class="anchor-heading" aria-labelledby="3-2-supervised-fine-tuning"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3-2. Supervised fine-tuning </h3> <p>ì´ë ‡ê²Œ initializationì„ ì§„í–‰í•œ í›„, labeled datasetì„ ì´ìš©í•˜ì—¬ parameterë“¤ì„ supervised target taskì— ë§ê²Œ ì¡°ì •í•œë‹¤. input $ x_1, â€¦, x_m $ê³¼ ê·¸ì— ëŒ€í•œ label yê°€ ìˆë‹¤ê³  ìƒê°í•  ë•Œ, inputì´ pre-trained modelì„ í†µê³¼í•˜ë©° activation $ h^m_l $ë¥¼ ì–»ê³ , W_y parameterê³¼ í•¨ê»˜ added linear output layerì— ë“¤ì–´ê°€ì„œ ìµœì¢…ì ìœ¼ë¡œ yë¥¼ ì˜ˆì¸¡í•˜ê²Œ ëœë‹¤.</p> <p>$ P(y | x_1, â€¦, x_m) = softmax(h^m_l W_y) \quad<br /> $</p> <p>ì¦‰, x_1ë¶€í„° x_m ê¹Œì§€ì˜ ì…ë ¥ê°’ì„ ê°€ì§€ê³  activationê³¼ parameterì„ ê³±í•´ì„œ softmaxë¥¼ ì·¨í•˜ì—¬, x_1 ~ x_m ì´ ì…ë ¥ê°’ìœ¼ë¡œ ë“¤ì–´ê°”ì„ ë•Œ y ê°€ ë„ì¶œë  í™•ë¥ ì„ êµ¬í•˜ëŠ” ê²ƒì´ë‹¤.</p> <p>ì´í›„, ì´ë¥¼ ëª¨ë“  input-labelì— ëŒ€í•´ ì§„í–‰í•˜ì—¬, ë¡œê·¸í•©ì„ êµ¬í•´ L_2(C)ë¥¼ êµ¬í•œë‹¤.</p> <p>$ L_2(C) = \sum_{(x,y)} \log P(y | x_1, â€¦, x_m) \quad $</p> <p>ì§ê´€ì ìœ¼ë¡œ ìƒê°í•˜ë©´, ëª¨ë¸ì´ yì— ëŒ€í•´ì„œ ë†’ì€ í™•ë¥ ì„ ì˜ˆì¸¡í–ˆë‹¤ë©´ L_2(C)ê°€ í° ê°’ì„ ê°€ì§ˆ ê²ƒì´ë‹¤. í•™ìŠµ ì‹œ ì´ë ‡ê²Œ ìµœëŒ€í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ íŒŒë¼ë¯¸í„°ê°€ ì¡°ì •ë  ê²ƒì´ê³ , ì´ëŠ” ëª¨ë¸ì´ target taskì— ëŒ€í•´ ë†’ì€ ì •í™•ë„ë¡œ ì˜ˆì¸¡ì„ í•œë‹¤ëŠ” ì˜ë¯¸ì´ë‹¤. ì¦‰, Loss Functionì´ë‹¤.</p> <p>ì¶”ê°€ì ìœ¼ë¡œ fine-tuningì„ í•  ë•Œ, language modelingì„ auxiliary objectiveë¡œ ì¶”ê°€í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤. ê·¸ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.</p> <ol> <li>supervised modelì˜ generalization ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤</li> <li>convergenceë¥¼ ê°€ì†í™”í•œë‹¤ (ë¹ ë¥´ê²Œ ì•ˆì •í™”ëœë‹¤ëŠ” ëœ»)</li> </ol> <p>ê·¸ë˜ì„œ unsupervised learningì„ í•  ë•Œ ì¼ë˜ L_1(C)ì™€ supervised fine-tuningí•  ë•Œ ë§Œë“  L_2(C)ë¥¼ ëª¨ë‘ ì‚¬ìš©í•œë‹¤ (L_1(C)ì—ëŠ” ê°€ì¤‘ì¹˜ë¥¼ ë¶™ì¸ë‹¤).</p> <p>$ L_3(C) = L_2(C) + \lambda \cdot L_1(C) \quad (5) $</p> <div class="callout"> L_1(C)ì— ê°€ì¤‘ì¹˜ë¥¼ ë¶™ì´ëŠ” ì´ìœ ? ëª¨ë¸ ì„±ëŠ¥ì„ ìµœì í™”í•˜ê¸° ìœ„í•¨. L2ëŠ” ì´ë¯¸ taskì— ìµœì í™”ê°€ ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, generalí•˜ê²Œ initialized ë˜ì–´ ìˆëŠ” ìƒíƒœì¸ L1ì„ ì¡°ì •í•´ì„œ íš¨ìœ¨ì„±ì„ ë†’ì¸ë‹¤. ë‘ L functionì˜ ê· í˜•ì„ ì¡°ì ˆí•˜ë©´ì„œ, ëª¨ë¸ì´ íŠ¹ì •í•œ ê³¼ì œì— ì¹˜ìš°ì¹˜ì§€ ì•Šë„ë¡ í•˜ëŠ” ê²ƒì´ë‹¤. (ê·¸ëƒ¥ ê°€ì¤‘ì¹˜ ê°€í•´ì„œ ë”í•˜ê¸°ë§Œ í•œë‹¤ë‹ˆ .. ì§ê´€ì ì´ë©´ì„œë„ ì´ë¡œ ì í•©ì´ ë˜ëŠ” ê²ƒë„ ì°¸ ì‹ ê¸° ..) </div> <p><br /></p> <h3 id="33-task-specific-input-transformations"> <a href="#33-task-specific-input-transformations" class="anchor-heading" aria-labelledby="33-task-specific-input-transformations"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3.3 Task-Specific input Transformations </h3> <p>text classificationê³¼ ê°™ì€ íƒœìŠ¤í¬ì— ëŒ€í•´ì„œëŠ” ìš°ë¦¬ê°€ ë°”ë¡œ fine-tuningí•˜ë©´ ì˜ ìˆ˜í–‰í•´ë‚¼ ìˆ˜ ìˆë‹¤. ê·¼ë° QA(ì§ˆë¬¸ì— ë‹µí•˜ê¸°)ë‚˜ TE(ì¶”ë¡ í•˜ê¸°)ëŠ” êµ¬ì¡°í™”ëœ inputì´ ìˆê³ (ë¬¸ì¥ ì§, ë¬¸ì„œ, ì§ˆë¬¸-ë‹µ), ìš°ë¦¬ì˜ pre-trained modelì€ ì•„ì˜ˆ contiguous sequence ë¡œ ì´ë£¨ì–´ì ¸ ìˆê¸° ë•Œë¬¸ì—, ì´ëŸ° íƒœìŠ¤í¬ê¹Œì§€ ì˜ ìˆ˜í–‰í•´ë‚´ê¸° ìœ„í•´ì„œëŠ” ì¢€ ìˆ˜ì •ì´ í•„ìš”í•  ê²ƒì´ë‹¤.</p> <p><strong>Textual entailment Task</strong> ë¥¼ ìœ„í•´ì„œ, premise <em>p</em>ì™€ hypothesis <em>h</em> í† í° ìˆœì„œë¥¼ ê²°í•©í•œë‹¤ (ì‚¬ì´ì— delimiter token ì¶”ê°€)</p> <p><strong>Similarity Task</strong> ë¥¼ ìœ„í•´ì„œ, ë‘ ë¬¸ì¥ì˜ ìŒ ìˆœì„œê°€ ì •í™•í•˜ê²Œ ì •í•´ì ¸ ìˆëŠ”ê²Œ ì•„ë‹ˆê¸° ë•Œë¬¸ì— delimiter tokenì„ ì¶”ê°€í•œ ë’¤ ê°ê° ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬í•´ì„œ ë‘ ê°œì˜ ì‹œí€€ìŠ¤ í‘œí˜„ì„ ë§Œë“ ë‹¤.</p> <p><strong>Question Answering and Commensense Reasoning Task</strong> ë¥¼ ìœ„í•´ì„œ, context document z, question q, ê°€ëŠ¥í•œ answerë“¤ {a_k}ë¥¼ ê°€ì§€ê³  ê²°í•©í•œ ë’¤, softmaxë¥¼ í†µí•´ output ë¶„í¬ë¥¼ ê³„ì‚°í•œë‹¤.</p><hr /> <h3> <a href="#33-task-specific-input-transformations" class="anchor-heading" aria-labelledby="33-task-specific-input-transformations"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> ğŸ”— Related Posts in NLP </h3> <ul> <li><a href="/nlp/react/">ReAct: Synergizing Reasoning and Acting in Language Models</a> (2025-06-08)</li> <li><a href="/nlp/batchapi/">ì¼ë°˜ APIì™€ Batch API ì‚¬ìš©í•˜ê¸°</a> (2025-04-01)</li> <li><a href="/nlp/colab-prompting/">Colabìœ¼ë¡œ í”„ë¡¬í”„íŒ…(Prompting)í•˜ê¸°</a> (2024-12-29)</li> <li><a href="/nlp/colab-finetune/">Colabìœ¼ë¡œ íŒŒì¸íŠœë‹(Fine-Tuning)í•˜ê¸°</a> (2024-12-29)</li> </ul> <nav class="post-nav"> <a class="prev" href="/nlp/batchapi/">â† ì¼ë°˜ APIì™€ Batch API ì‚¬ìš©í•˜ê¸°</a> <a class="next" href="/nlp/react/">ReAct: Synergizing Reasoning and Acting in Language Models â†’</a> </nav> </main> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
