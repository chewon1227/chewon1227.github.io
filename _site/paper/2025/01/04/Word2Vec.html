<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav ul li a { background-image: none; } </style> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>[Word2Vec] Efficient Estimation of Word Representations in Vector Space (2013) | Rachel Docs</title> <meta name="generator" content="Jekyll v4.3.4" /> <meta property="og:title" content="[Word2Vec] Efficient Estimation of Word Representations in Vector Space (2013)" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Intro" /> <meta property="og:description" content="Intro" /> <link rel="canonical" href="http://localhost:4000/paper/2025/01/04/Word2Vec.html" /> <meta property="og:url" content="http://localhost:4000/paper/2025/01/04/Word2Vec.html" /> <meta property="og:site_name" content="Rachel Docs" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2025-01-04T00:00:00+09:00" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="[Word2Vec] Efficient Estimation of Word Representations in Vector Space (2013)" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-01-04T00:00:00+09:00","datePublished":"2025-01-04T00:00:00+09:00","description":"Intro","headline":"[Word2Vec] Efficient Estimation of Word Representations in Vector Space (2013)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/paper/2025/01/04/Word2Vec.html"},"url":"http://localhost:4000/paper/2025/01/04/Word2Vec.html"}</script> <!-- End Jekyll SEO tag --> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> Rachel Docs </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/posts" class="nav-list-link">Posts by Category</a></li><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Rachel Docs" aria-label="Search Rachel Docs" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://github.com/just-the-docs/just-the-docs-template" class="site-button" > Template Repository </a> </li> </ul> </nav> </div> <div class="main-content-wrap"> <div id="main-content" class="main-content"> <main> <h1>[Word2Vec] Efficient Estimation of Word Representations in Vector Space (2013)</h1> <h2 id="intro"> <a href="#intro" class="anchor-heading" aria-labelledby="intro"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Intro </h2> <p>NLP ì‹œìŠ¤í…œë“¤ì´ ë³´í†µ ë‹¨ì–´ë¥¼ atomic unitìœ¼ë¡œ ë³´ê³  ìˆë‹¤ëŠ” ì ì— ëŒ€í•´ ë¬¸ì œì œê¸°ë¥¼ í•˜ì—¬, word2vec êµ¬ì¡°ë¥¼ ë§Œë“¤ì–´ë‚¸ ë…¼ë¬¸ì´ë‹¤. ê¸°ì¡´ì— ì·¨í–ˆë˜ ë°©ì‹ì€ ë‹¨ì–´ë“¤ ìœ ì‚¬ì„±ì— ëŒ€í•œ notionë„ ì—†ì´, ê·¸ëƒ¥ ì•„ì˜ˆ ê°ê° ë”°ë¡œ ì‹¬í”Œí•˜ê²Œ êµ¬ì„±í–ˆë‹¤. ì´ëŠ” ë‹¨ìˆœí•˜ê³  í¸í•˜ê¸´ í•˜ì§€ë§Œ ë°ì´í„°ì…‹ì´ í•œì •ë˜ì–´ ìˆê³  ë§ì€ ë°ì´í„°ì…‹ì—ì„œ ì•„ì§ í•œê³„ì— ë¨¸ë¬´ë¥´ê³  ìˆê¸°ì— ìƒˆë¡œìš´ êµ¬ì¡°ê°€ í•„ìš”í•˜ë‹¤.</p> <ol> <li>N-gramì— ì´ì–´ ê°€ì¥ ì„±ê³µì ì´ì—ˆë˜ êµ¬ì¡°ëŠ” ì‹ ê²½ë§ êµ¬ì¡°ì˜€ê¸°ì—, ì´ë¥¼ ì°¨ìš©í•œë‹¤.</li> <li>ë‘ ê°€ì§€ expectationì„ ë°”íƒ•ìœ¼ë¡œ í•œë‹¤. <ol> <li>similar wordëŠ” close to each otherí•  ê²ƒì´ë‹¤.</li> <li>ë‹¨ì–´ë“¤ì´ ì—¬ëŸ¬ ìœ ì‚¬ì„± ì •ë„ë¥¼ ê°€ì§ˆ ê²ƒì´ë‹¤ (multiple degrees of similarity)</li> </ol> </li> </ol> <p>ë†€ëê²Œë„ word representationì˜ ìœ ì‚¬ì„±ì€ ë‹¨ìˆœí•œ êµ¬ë¬¸ ê·œì¹™ë¥¼ í›¨ì”¬ ë›°ì–´ë„˜ëŠ”ë‹¤ëŠ” ê²ƒì´ ë°í˜€ì¡Œë‹¤. ì˜ˆë¥¼ ë“¤ë©´, vector(king) - vector(man) + vector(woman) ì„ í•˜ë©´ vector(queen)ì— ê°€ì¥ ê°€ê¹Œìš´ ê²°ê³¼ê°€ ë‚˜ì˜¨ë‹¤ëŠ” ê²ƒì´ë‹¤.</p> <h2 id="model-architectures"> <a href="#model-architectures" class="anchor-heading" aria-labelledby="model-architectures"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Model Architectures </h2> <p>ì•ìœ¼ë¡œ, ëª¨ë¸ í›ˆë ¨ì˜ ë³µì¡ë„ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„ëœë‹¤.</p> <p>[O = E \times T \times Q,]</p> <p>EëŠ” training epochs, TëŠ” í›ˆë ¨ ì„¸íŠ¸ì˜ ê°œìˆ˜ì´ê³  QëŠ” ëª¨ë¸ êµ¬ì¡°ì—ì„œ ì •ì˜ëœë‹¤. ì¼ë°˜ì ìœ¼ë¡œ E = 3-50, T = 1 billion ì •ë„ë¥¼ ì·¨í•œë‹¤. SGDì™€ back propagationì„ í†µí•´ í•™ìŠµëœë‹¤.</p> <h3 id="feedfoward-neural-net-language-model"> <a href="#feedfoward-neural-net-language-model" class="anchor-heading" aria-labelledby="feedfoward-neural-net-language-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Feedfoward Neural Net Language Model </h3> <p>ëª¨ë¸ì€ input layer, projection layer, hidden layer, output layerìœ¼ë¡œ êµ¬ì„±ì´ ëœë‹¤.</p> <p><strong>input layer</strong></p> <p>í•´ë‹¹ ë‹¨ì–´ì˜ ì´ì „ Nê°œì˜ ë‹¨ì–´ë“¤ì„ inputìœ¼ë¡œ ë°›ëŠ”ë‹¤. ê° ë‹¨ì–´ë“¤ì€ 1-of-V codingì„ í†µí•´ ì¸ì½”ë”©ëœë‹¤.</p> <p><strong>projection layer</strong></p> <p>input layerì˜ ë‹¨ì–´ë“¤ì„ Dì°¨ì›ìœ¼ë¡œ projectioní•œë‹¤. ì¦‰, projection layerì˜ í¬ê¸°ëŠ” NxDì´ë‹¤. ì—¬ê¸°ì„œ Nê°œ ë‹¨ì–´ì— ëŒ€í•´ ë™ì¼í•œ projection layerì„ ì‚¬ìš©í•œë‹¤.</p> <p><strong>hidden layer</strong></p> <p>ë°€ì§‘ëœ ìƒíƒœì´ê¸°ì— ê³„ì‚°ì´ ë³µì¡í•  ìˆ˜ ìˆë‹¤.</p> <p><strong>output layer</strong></p> <p>ì¶œë ¥ ë‹¨ì–´ Vì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ê³„ì‚°í•œë‹¤.</p> <p>ê° í›ˆë ¨ ì„¸íŠ¸ì˜ ê³„ì‚° ë³µì¡ë„ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.</p> <p>[Q = N \times D + N \times D \times H + H \times V,]</p> <p>ì—¬ê¸°ì„œ $ N\times D$ëŠ” input â†’ projection, $N \times D \times H$ëŠ” projection â†’ hidden, $H \times V$ëŠ” hidden â†’ output ë¶€ë¶„ì˜ ê³„ì‚°ì„ ì˜ë¯¸í•œë‹¤. ì´ë•Œ, ë§ˆì§€ë§‰ ë¶€ë¶„ì—ì„œ outputì˜ í™•ë¥ ë¶„í¬ ê³„ì‚°ì„ ìœ„í•´ ì›ë˜ ë‹¨ì–´ í¬ê¸° ë§Œí¼ì¸ V ë§Œí¼ ê³„ì‚°ì„ í•˜ê²Œ ë˜ë¯€ë¡œ, ë‹¨ì–´ë“¤ì˜ ìˆ˜ê°€ ë§ìœ¼ë©´ ë³‘ëª©ì´ ìƒê¸¸ ìˆ˜ ìˆë‹¤.</p> <p>ì´ë¥¼ ì¤„ì´ê¸° ìœ„í•´ Hierarchical Softmaxì´ ì œì•ˆëœë‹¤. ì´ëŠ” ë‹¨ì–´ë“¤ì„ Huffman binary treeë¡œ í‘œí˜„í•œë‹¤. ë¹ˆë„ê°€ ë†’ì€ ë‹¨ì–´ë¥¼ ë” ì§§ì€ ì½”ë“œë¡œ í‘œí˜„í•¨ìœ¼ë¡œì„œ ê³„ì‚°ì˜ ìˆ˜ë¥¼ í™• ì¤„ì—¬ë²„ë¦°ë‹¤.</p> <h3 id="recurrent-neural-net-language-model"> <a href="#recurrent-neural-net-language-model" class="anchor-heading" aria-labelledby="recurrent-neural-net-language-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Recurrent Neural Net Language Model </h3> <p>Recurrent NNLMì€ feedforward NNLMì˜ í•œê³„ì , íŠ¹íˆ ë§¥ë½ì˜ ê¸¸ì´ë¥¼ êµ¬ì²´í™”í•  í•„ìš”ì„±ì„ ë³´ì™„í•˜ê¸° ìœ„í•´ ë§Œë“¤ì–´ì¡Œë‹¤. ë˜í•œ, ì´ë¡ ì ìœ¼ë¡œ RNNë“¤ì€ ë³µì¡í•œ íŒ¨í„´ë“¤ì„ ë” íš¨ìœ¨ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤. RNN ëª¨ë¸ì€ projection ëª¨ë¸ì´ ì—†ê³ , input, hidden, output layerë§Œ ê°€ì§€ê³  ìˆë‹¤. RNNì€ hidden layerì„ time-delayed connectionì„ í†µí•´ ê³„ì† ì—°ê²°í•´ë‚˜ê°€ì„œ short term memoryë¥¼ ê°€ì§€ê²Œ ëœë‹¤.</p> <p>RNN ëª¨ë¸ì˜ ê³„ì‚° ë³µì¡ë„ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.</p> <p>[Q = H \times H + H \times V,]</p> <h2 id="new-log-linear-models"> <a href="#new-log-linear-models" class="anchor-heading" aria-labelledby="new-log-linear-models"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> New Log-Linear Models </h2> <p>ê³„ì‚° ë³µì¡ë„ë¥¼ ì¤„ì´ê¸° ìœ„í•œ ë‘ ê°€ì§€ êµ¬ì¡°ë¥¼ ì œì•ˆí•œë‹¤.</p> <p>ì§€ê¸ˆê¹Œì§€ ë‚˜ì˜¨ ëª¨ë¸ë“¤ì˜ ê³„ì‚° ë³µì¡ë„ëŠ” hidden layerì˜ non-linearí•œ êµ¬ì¡° ë•Œë¬¸ì´ì—ˆë‹¤. ê·¸ë ‡ë‹¤ê³  ì´ êµ¬ì¡°ë¥¼ ì•„ì˜ˆ ë°°ì œí•˜ê¸°ì—ëŠ” ì´ non-linearí•œ êµ¬ì¡°ê°€ ì‹ ê²½ë§ êµ¬ì¡°ì˜ ë©”ì¸ í¬ì¸íŠ¸ì´ê¸° ë•Œë¬¸ì— ê·¸ëŸ´ ìˆ˜ëŠ” ì—†ë‹¤.</p> <p>ì¦‰, ìš°ë¦¬ì˜ ëª©í‘œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤</p> <ol> <li>neural networkë§Œí¼ ì •í™•í•˜ì§€ëŠ” ëª»í•´ë„,</li> <li>íš¨ìœ¨ì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” êµ¬ì¡°ë¥¼ ì°¾ì.</li> </ol> <h3 id="continuous-bag-of-words-model"> <a href="#continuous-bag-of-words-model" class="anchor-heading" aria-labelledby="continuous-bag-of-words-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Continuous Bag-of-Words Model </h3> <p>ì²˜ìŒìœ¼ë¡œ ì œì•ˆëœ êµ¬ì¡°ëŠ” BoWì´ë‹¤. ì´ êµ¬ì¡°ëŠ” non-linear hidden layerì€ ì—†ê³  projection layerì´ ëª¨ë‘ ê³µìœ ë˜ëŠ” í˜•íƒœì´ë‹¤. ì¦‰, ëª¨ë“  ë‹¨ì–´ì— ëŒ€í•´ same projection layerì´ ìˆëŠ” ê²ƒì´ë‹¤.</p> <p>ê·¸ëŸ¬ë‚˜ Continuous BoWì˜ ê²½ìš° í˜„ ë‹¨ì–´ ì´í›„ì˜ ë‹¨ì–´ë“¤ë„ ì´ìš©ì„ í•˜ê¸° ëŒ€ë¬¸ì—, íƒœìŠ¤í¬ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤. 4ê°œì˜ ì´ì „ ë‹¨ì–´ì™€ 4ê°œì˜ ì´í›„ ë‹¨ì–´ë“¤ì„ ì‚¬ìš©í•˜ì—¬ í˜„ì¬ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•œë‹¤.</p> <h3 id="continuous-skip-gram-model"> <a href="#continuous-skip-gram-model" class="anchor-heading" aria-labelledby="continuous-skip-gram-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Continuous Skip-gram Model </h3> <p>ë‘ ë²ˆì§¸ êµ¬ì¡°ëŠ” CBOWì™€ ìœ ì‚¬í•˜ì§€ë§Œ, ë°˜ëŒ€ ëŠë‚Œì´ë‹¤. ë§¥ë½ì„ í†µí•´ í˜„ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ê°™ì€ ë¬¸ì¥ì˜ ë‹¤ë¥¸ ë‹¨ì–´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¨ì–´ì˜ ë¶„ë¥˜ë¥¼ ìµœëŒ€í™”í•œë‹¤. ì •í™•íˆ ë§í•˜ë©´, í˜„ì¬ ë‹¨ì–´ë¥¼ ê°€ì§€ê³  ì•ë’¤ ë‹¨ì–´ë“¤ì„ ì˜ˆì¸¡í•œë‹¤. ê·¸ ì˜ˆì¸¡í•˜ëŠ” ë²”ìœ„ë¥¼ ëŠ˜ë¦¬ë©´ ë‹¹ì—°íˆ ì§ˆì´ í–¥ìƒë˜ê² ì§€ë§Œ ê³„ì‚°ì´ ë³µì¡í•´ì§„ë‹¤. ì§€ê¸ˆ ëª©ì ì€ ê³„ì‚° ë³µì¡ë„ë¥¼ ì¤„ì´ê¸° ìœ„í•œ ê²ƒì´ë¯€ë¡œ ì ì ˆí•œ ì§€ì ì´ í•„ìš”í•˜ë‹¤.</p><hr /> <h3> <a href="#continuous-skip-gram-model" class="anchor-heading" aria-labelledby="continuous-skip-gram-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> ğŸ”— Related Posts in Paper </h3> <ul> <li><a href="/paper/2025/01/07/Attention.html">[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015)</a> (2025-01-07)</li> <li><a href="/paper/2025/01/06/Seq2Seq.html">[Seq2Seq] Sequence to Sequence Learning with Neural Networks (2014)</a> (2025-01-06)</li> <li><a href="/paper/2025/01/05/LSTM.html">[LSTM] Long Short Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling (2014)</a> (2025-01-05)</li> <li><a href="/paper/2025/01/03/RNN.html">[RNN] Recurrent neural network based language model (2010)</a> (2025-01-03)</li> </ul> <nav class="post-nav"> <a class="prev" href="/paper/2025/01/03/RNN.html">â† [RNN] Recurrent neural network based language model (2010)</a> <a class="next" href="/paper/2025/01/05/LSTM.html">[LSTM] Long Short Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling (2014) â†’</a> </nav> </main> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
