<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav ul li a { background-image: none; } </style> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>[Seq2Seq] Sequence to Sequence Learning with Neural Networks (2014) | Rachel Docs</title> <meta name="generator" content="Jekyll v4.3.4" /> <meta property="og:title" content="[Seq2Seq] Sequence to Sequence Learning with Neural Networks (2014)" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Intro" /> <meta property="og:description" content="Intro" /> <link rel="canonical" href="http://localhost:4000/paper/2025/01/06/Seq2Seq.html" /> <meta property="og:url" content="http://localhost:4000/paper/2025/01/06/Seq2Seq.html" /> <meta property="og:site_name" content="Rachel Docs" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2025-01-06T00:00:00+09:00" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="[Seq2Seq] Sequence to Sequence Learning with Neural Networks (2014)" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-01-06T00:00:00+09:00","datePublished":"2025-01-06T00:00:00+09:00","description":"Intro","headline":"[Seq2Seq] Sequence to Sequence Learning with Neural Networks (2014)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/paper/2025/01/06/Seq2Seq.html"},"url":"http://localhost:4000/paper/2025/01/06/Seq2Seq.html"}</script> <!-- End Jekyll SEO tag --> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> Rachel Docs </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/posts" class="nav-list-link">Posts by Category</a></li><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Rachel Docs" aria-label="Search Rachel Docs" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://github.com/just-the-docs/just-the-docs-template" class="site-button" > Template Repository </a> </li> </ul> </nav> </div> <div class="main-content-wrap"> <div id="main-content" class="main-content"> <main> <h1>[Seq2Seq] Sequence to Sequence Learning with Neural Networks (2014)</h1> <h2 id="intro"> <a href="#intro" class="anchor-heading" aria-labelledby="intro"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Intro </h2> <p>DNN은 1) speech recognition과 2) visual object recognition을 잘 수행하는 아주 강력한 머신러닝 모델이다. 그러나, 인코더 벡터의 차원이 제한되어 있다는 점이 가장 큰 문제점이었다. 왜냐면 미리 그 벡터의 차원을 알 수 없는 (lengths are not known a-priori) sequence들을 잘 표현할 줄 아는 것이 중요하기 때문이다.</p> <p>그래서, Seq2Seq에서는 두 개의 LSTM을 이용한다.</p> <ul> <li>input을 읽는 LSTM : 한 번에 하나의 timestep를 읽어나가며 large fixed-dimensional vector를 만든다</li> <li>output을 처리하는 LSTM : 그 large vector에서 output sequence를 추출한다</li> </ul> <p>특히. 두 번째 LSTM은 <code class="language-plaintext highlighter-rouge">RNN language model</code>이다 (input sequence 조건에 따른다는 점만 제외하고). <code class="language-plaintext highlighter-rouge">RNN language model</code>은 주어진 이전 단어들의 시퀀스를 기반으로 다음 단어를 예측한다. 예를 들어, i am 이 있으면 다음에 going이 나올 확률이 얼마나 되는지를 분포를 통해 예측하는 것이다. 방식이 유사하긴 하지만 참조하는 시퀀스가 ‘주어진 이전 단어들’이 아닌, ‘input LSTM에서 읽어낸 large vector’이라는 점이 다르다.</p> <h2 id="the-model"> <a href="#the-model" class="anchor-heading" aria-labelledby="the-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Model </h2> <h3 id="lstm을-사용하는-이유"> <a href="#lstm을-사용하는-이유" class="anchor-heading" aria-labelledby="lstm을-사용하는-이유"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> LSTM을 사용하는 이유 </h3> <p>RNN은 sequence를 처리할 때, FFNN의 가장 자연스러운 generalization이다. 일반적으로 다음 수식을 통해 계산이 된다.</p> <p>[ h_t = \sigma(W_{hx}x_t + W_{hh}h_{t-1}), y_t = W_{yh}h_t ]</p> <p>RNN은 input과 output의 길이가 미리 알려져 있을 때, sequence를 쉽게 매핑할 수 있다. 그러나, input과 output이 서로 다른 길이를 가지고 있거나, 일대일 매칭이 아닌 경우 (non-monotonic relationships) RNN을 적용하기 어렵다.</p> <p>일반적인 sequence learning은 먼저 한 RNN으로 input sequence를 fixed-size vector로 만들고 그 다음 다른 RNN을 통해 target sequence로 매핑시키는 것이다. RNN은 전체 맥락을 모두 제공받기 때문에 논리 상으로는 가능하긴 한데, long term dependencies 이슈로 RNN을 훈련하는 것 자체가 어려울 수 있다. 그러나 LSTM은 long-range도 잘 하므로 LSTM 두 개로 모델을 구성한 것이다.</p> <h3 id="lstm의-목적"> <a href="#lstm의-목적" class="anchor-heading" aria-labelledby="lstm의-목적"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> LSTM의 목적 </h3> <div class="table-wrapper"><table> <tbody> <tr> <td>LSTM의 목표는 조건부확률 $p(y_1, \ldots, y_{T’})</td> <td>(x_1, \ldots, x_T)$를 추정하는 것이다. ($x$들은 입력 시퀀스, $y$들은 그에 대응하는 출력 시퀀스, 서로 길이는 다를 수 있다는 것을 가정)</td> </tr> </tbody> </table></div> <p>이 조건부확률을 구하기 위해 다음과 같은 과정을 거친다.</p> <ol> <li>input sequence의 fixed dimensional representation를 구한다 - LSTM의 마지막 hidden state에 있을 것임. hidden state에 맥락이 차근차근 저장이 되어 오고 있었을 것이므로.</li> <li>LSTM-LM 형식을 사용해서 $y_1, \ldots, y_{T’}$의 확률을 구한다</li> </ol> <p>LSTM-LM 형식은 다음과 같다.</p> <p>[ p(y_1, \ldots, y_{T’} | x_1, \ldots, x_T) = \prod_{t=1}^{T’} p(y_t | v, y_1, \ldots, y_{t-1}) \tag{1} ]</p> <p>Seq2Seq의 특이점은 바로 <EOS> 토큰이다.</EOS></p> <p>각 문장은 끝에 special end-of-sentence symbol인 <EOS>를 달게 된다. 이를 통해 모델이 sequence가 언제 끝났는지 알 수 있고, 다양한 길이의 sequence를 처리할 수 있게 된다.</EOS></p> <p>예를 들어 input 쪽 LSTM은 “A”, “B”, “C”, <EOS>를 처리하고, output 쪽 LSTM은 이를 기반으로 “W’, “X”, “Y”, “Z”, <EOS>의 확률 분포를 계산한다. 이 출력 단어들의 확률 분포를 기반으로 softmax를 취해 각 단어에 대한 확률을 계산한다.</EOS></EOS></p> <h3 id="seq2seq의-differ-point"> <a href="#seq2seq의-differ-point" class="anchor-heading" aria-labelledby="seq2seq의-differ-point"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Seq2Seq의 differ point </h3> <p>Seq2Seq에는 세 가지 중요한 포인트가 있다.</p> <ol> <li><strong>두 개의 서로 다른 LSTM을 사용한다.</strong></li> </ol> <p>하나는 input sequence를 위한 것이고, 다른 하나는 output sequence를 위한 것이다. 이렇게 하면 모델 파라미터도 수용 가능한 선 정도로 늘어나고, 두 개의 언어 세트를 동시에 훈련하기에도 자연스럽고 좋다.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>모델 파라미터랑 무슨 관련이 있어? 

만약 동일한 LSTM을 사용한다면, 이 LSTM은 입/출력을 모두 처리할 수 있도록 만들어져야 한다. 이말인즉슨, LSTM이 해야 되는 일이 더 많아지니 더 많은 파라미터를 학습해야 한다는 뜻이다. 
서로 다른 LSTM을 사용할 경우, 각 LSTM은 자신이 담당하는 작업 (입력 or 출력) 만 진행하면 되니 적절한 양의 파라미터로 승부할 수 있다. 
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>두 개의 언어 세트를 동시에 훈련한다는 게 뭐야? 

LSTM이 두개니까, 각 LSTM이 각 언어를 전담해서 학습할 수 있다. 추가적으로, 확장성도 가질 수 있을 것이다. 같은 인코더를 두고, 여러 디코더를 사용하여 서로 다른 출력 언어를 처리할 수도 있다. 
</code></pre></div></div> <ol> <li><strong>4 layers를 가진 LSTM을 사용한다.</strong></li> </ol> <p>deep LSTM이 shallow LSTM보다 훨씬 성능이 좋다는 것을 발견하였다.</p> <ol> <li><strong>input sentence를 뒤집을 때 성능이 더 좋다.</strong></li> </ol> <p>예를 들어 문장 a, b, c를 <em>**</em>α, β, γ 와 매핑하는 것보다 c, b, a를 α, β, γ와 매핑하는 것이 더 좋다는 것이다 ( α, β, γ는 각각 a, b, c의 번역이다). 이렇게 했을 때 α의 뜻이 a에 더 가깝고, β의 뜻이 b에 더 가깝고, γ의 뜻이 c에 더 가깝다는 것이다. 또한, SGD가 더 잘 작동한다.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>왜 그런거지? 

Seq2Seq 모델은 input sequence를 읽은 후 -&gt; 고정된 크기의 large vector로 요약되어 -&gt; 디코더가 이를 기반으로 output sequence를 만들어낸다. 
즉, input sentence의 앞부분은 초반에 처리가 될 것이고, 뒤의 문장들이 다 처리가 된 이후에 디코더가 이를 활용할 것이다. 결국 문장이 길어지게 되면 그 문맥이 희석되어 input-output dependency가 약해질 수 있는 것 !! 

SGD에서 생각을 해보면, 순서를 뒤집어서 위와 같이 더 잘 동작하게 될 때 alignment가 강화되어 vanishing gradient problem (기울기 소실 문제) 가 완화될 것이다. 특히, 긴 시퀀스를 처리할 때 더더욱 그럴 것 !! loss function이 더 안정적으로 수렴하게 되어 훨 효율적이다. 
</code></pre></div></div><hr /> <h3> <a href="#seq2seq의-differ-point" class="anchor-heading" aria-labelledby="seq2seq의-differ-point"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 🔗 Related Posts in Paper </h3> <ul> <li><a href="/paper/2025/01/07/Attention.html">[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015)</a> (2025-01-07)</li> <li><a href="/paper/2025/01/05/LSTM.html">[LSTM] Long Short Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling (2014)</a> (2025-01-05)</li> <li><a href="/paper/2025/01/04/Word2Vec.html">[Word2Vec] Efficient Estimation of Word Representations in Vector Space (2013)</a> (2025-01-04)</li> <li><a href="/paper/2025/01/03/RNN.html">[RNN] Recurrent neural network based language model (2010)</a> (2025-01-03)</li> </ul> <nav class="post-nav"> <a class="prev" href="/paper/2025/01/05/LSTM.html">← [LSTM] Long Short Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling (2014)</a> <a class="next" href="/paper/2025/01/07/Attention.html">[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015) →</a> </nav> </main> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
