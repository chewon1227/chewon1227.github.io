<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav ul li a { background-image: none; } </style> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015) | Rachel Docs</title> <meta name="generator" content="Jekyll v4.3.4" /> <meta property="og:title" content="[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015)" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="1. Intro" /> <meta property="og:description" content="1. Intro" /> <link rel="canonical" href="http://localhost:4000/paper/2025/01/07/Attention.html" /> <meta property="og:url" content="http://localhost:4000/paper/2025/01/07/Attention.html" /> <meta property="og:site_name" content="Rachel Docs" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2025-01-07T00:00:00+09:00" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015)" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-01-07T00:00:00+09:00","datePublished":"2025-01-07T00:00:00+09:00","description":"1. Intro","headline":"[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/paper/2025/01/07/Attention.html"},"url":"http://localhost:4000/paper/2025/01/07/Attention.html"}</script> <!-- End Jekyll SEO tag --> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> Rachel Docs </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/posts" class="nav-list-link">Posts by Category</a></li><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Rachel Docs" aria-label="Search Rachel Docs" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://github.com/just-the-docs/just-the-docs-template" class="site-button" > Template Repository </a> </li> </ul> </nav> </div> <div class="main-content-wrap"> <div id="main-content" class="main-content"> <main> <h1>[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015)</h1> <h2 id="1-intro"> <a href="#1-intro" class="anchor-heading" aria-labelledby="1-intro"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1. Intro </h2> <p>Neural Machine Translation ì€ ê¸°ê³„ë²ˆì—­ì—ì„œ ìƒˆë¡­ê²Œ ë“±ì¥í•˜ëŠ” ì ‘ê·¼ì´ë‹¤.</p> <p>ê¸°ì¡´ì— ìˆì—ˆë˜ Traditional Phrase-based translation systemì˜ ê²½ìš° sub componentë“¤ì´ ìˆê³  ê°ê° tuneë˜ì–´ì•¼ í–ˆì§€ë§Œ, ì´ neural machine translationì€ 1ê°œì˜ ê±°ëŒ€í•œ ì‹ ê²½ë§ êµ¬ì¡°ì´ë‹¤ (í™•ì‹¤íˆ í•™ìŠµ ì‹œ íš¨ìœ¨ì ì¼ ê²ƒ)</p> <p>ì¼ë°˜ì ìœ¼ë¡œ ê¸°ê³„ë²ˆì—­ ëª¨ë¸ì´ë¼ê³  í•˜ë©´ encoder-decoder í˜•ì‹ì´ê³ , ê° ì–¸ì–´ê°€ encoder, decoderì„ ê°ê° ì°¨ì§€í•œë‹¤. encoderì´ ê¸°ì¡´ ë¬¸ì¥ì„ fixed-length ë²¡í„°ë¡œ ì½ì–´ë“¤ì¸ í›„, decoderì´ ê·¸ì— ëŒ€í•œ ë²ˆì—­ì„ ë„ì¶œí•œë‹¤. ì—¬ê¸°ì„œ <strong>fixed-length ë²¡í„°ë¡œ ì½ì–´ë“¤ì¸ë‹¤ëŠ” ì </strong>ì´, ê¸´ ë¬¸ì¥ì„ ëŒ€í•˜ê¸° ì–´ë µë‹¤ëŠ” ì ì—ì„œ í•œê³„ì ì´ë‹¤. íŠ¹íˆ í›ˆë ¨ ì½”í¼ìŠ¤ì—ì„œ ê¸´ ë¬¸ì¥ì´ ìˆì„ ì‹œ ì œëŒ€ë¡œ í•™ìŠµì´ ì•ˆë  ê²ƒì´ë‹¤.</p> <p>ê·¸ë˜ì„œ alignê³¼ translateë¥¼ ë™ì‹œì— í•™ìŠµí•˜ëŠ” encoder-decoder modelì„ ì œì‹œí•œë‹¤.</p> <ul> <li>translationìœ¼ë¡œ ë‹¨ì–´ë¥¼ ìƒì„±í•´ì„œ ì œì‹œí•¨</li> <li>ê°€ì¥ ê´€ë ¨ëœ ì •ë³´ê°€ ì§‘ì¤‘ë˜ì–´ ìˆëŠ” <code class="language-plaintext highlighter-rouge">source sentence</code>ì—ì„œì˜ <code class="language-plaintext highlighter-rouge">set of positions</code> ë¥¼ íƒìƒ‰í•¨</li> <li><code class="language-plaintext highlighter-rouge">source position</code>ê³¼ ì´ì „ì— ìƒì„±ëœ ëª¨ë“  target words ë¥¼ ê¸°ë°˜ìœ¼ë¡œ target wordë¥¼ ì˜ˆì¸¡í•¨</li> </ul> <p>íŠ¹íˆ ê°€ì¥ ì£¼ëª©í• ë§Œí•œ íŠ¹ì§•ì€ fixed-length êµ¬ì¡°ê°€ ì•„ë‹ˆë¼ëŠ” ê²ƒì´ë‹¤. ì¦‰, ê·¸ ê¸¸ì´ì— ë§ì¶°ì„œ ìë¥¼ í•„ìš”ê°€ ì—†ì–´ì¡Œìœ¼ë‹ˆ ê¸´ ë¬¸ì¥ì— ë”ìš± ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë½ë‚¼ ê²ƒì´ë‹¤.</p> <h2 id="2-background"> <a href="#2-background" class="anchor-heading" aria-labelledby="2-background"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2. Background </h2> <p>í™•ë¥ ì  ê´€ì ì—ì„œ ë³´ë©´ ê¸°ê³„ë²ˆì—­ì€, source sentence xì— ëŒ€í•´ì„œ target sentenceì˜ conditional probability yë¥¼ ìµœëŒ€í™”í•˜ëŠ” ê²ƒì´ë‹¤. ì´ë¥¼ ìœ„í•´ ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ í™œìš©í•˜ëŠ” ê²ƒì´ ëŒ€ë‘ë˜ì—ˆê³ , íŠ¹íˆ RNNì„ ë‘ê°œ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ëœë‹¤.</p> <ul> <li>í•œ RNNì€ ë‹¤ì–‘í•œ ê¸¸ì´ì˜ source sentenceë¥¼ fixed-length ë²¡í„°ë¡œ encodeí•˜ëŠ” ë°ì— ì‚¬ìš©</li> <li>ë‚˜ë¨¸ì§€ RNNì€ ë‹¤ì‹œ ë‹¤ì–‘í•œ ê¸¸ì´ì˜ target sentenceë¡œ decodeí•˜ëŠ” ë°ì— ì‚¬ìš©</li> </ul> <p>ì¦‰, ì •ë¦¬í•˜ë©´ <code class="language-plaintext highlighter-rouge">variable-length â†’ fixed length â†’ variable-length</code> ë¡œ ê°€ëŠ” ê²ƒì´ë‹¤.</p> <h3 id="2-1-rnn-encoder-decoder"> <a href="#2-1-rnn-encoder-decoder" class="anchor-heading" aria-labelledby="2-1-rnn-encoder-decoder"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2-1. RNN Encoder-Decoder </h3> <p>encoderì´ input sentenceë¥¼ ì½ëŠ”ë‹¤ ($\x = (x_1, \ldots, x_{T_x})$ ë¥¼ c^2ë¡œ ë³€í™˜) . hidden layerì€ ì¼ë°˜ì ìœ¼ë¡œ $\h_t = f(x_t, h_{t-1})$ ì™€ ê°™ì€ í˜•íƒœë¡œ êµ¬ì„±ëœë‹¤. ê·¸ë¦¬ê³ </p> <p>[ c = q({h_1, \ldots, h_{T_x}}) ]</p> <p>ë¥¼ í†µí•´ context vector cë¥¼ ê³„ì‚°í•œë‹¤.</p> <p>decoderì€ cì™€ ì´ì „ì— ë§Œë“¤ì–´ì§„ ë‹¨ì–´ë“¤ ( {y_1, \ldots, y_{tâ€™-1}} ) ì„ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒ ë‹¨ì–´ì¸ yë¥¼ ì˜ˆì¸¡í•œë‹¤.</p> <p>[ p(y) = \prod_{t=1}^{T} p(y_t | {y_1, \ldots, y_{t-1}}, c), ]</p> <p>[ p(y_t | {y_1, \ldots, y_{t-1}}, c) = g(y_{t-1}, s_t, c), ]</p> <p>ì—¬ê¸°ì„œ í•¨ìˆ˜ gëŠ” í™•ë¥ ì„ ëŒì–´ë‚´ê¸° ìœ„í•œ ë¹„ì„ í˜•í•¨ìˆ˜ê°€ ë  ê²ƒì»ë‹¤.</p> <h2 id="3-learning-to-align-and-translate"> <a href="#3-learning-to-align-and-translate" class="anchor-heading" aria-labelledby="3-learning-to-align-and-translate"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3. Learning to Align and Translate </h2> <p>alignê³¼ translateë¥¼ ì–´ë–»ê²Œ ë™ì‹œì— í•™ìŠµí•  ìˆ˜ ìˆì„ê¹Œ? ì´ë¥¼ ìœ„í•´ ìƒˆë¡œìš´ êµ¬ì¡°ë¥¼ ë„ì…í•œë‹¤.</p> <ul> <li>encoder : bidrectional RNN</li> <li>decoder : source sentenceë¥¼ íƒìƒ‰í•˜ëŠ” êµ¬ì¡°ë¥¼ ëª¨ë°©</li> </ul> <h3 id="3-1-decoder"> <a href="#3-1-decoder" class="anchor-heading" aria-labelledby="3-1-decoder"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3-1. Decoder </h3> <p>ê¸°ì¡´ RNN Encoder-Decoder ëª¨ë¸ì—ì„œëŠ”</p> <p>[ p(y) = \prod_{t=1}^{T} p(y_t | {y_1, \ldots, y_{t-1}}, c), ]</p> <p>ë¡œ ì •ì˜í–ˆë˜ p(y)ë¥¼ ì´ì œëŠ”</p> <p>[ p(y_i | y_1, \ldots, y_{i-1}, x) = g(y_{i-1}, s_i, c_i), ]</p> <p>ë¡œ ì •ì˜í•œë‹¤. ê°€ì¥ í° ì°¨ì´ì ì€, ê° ë‹¨ì–´ $\y_i$ë§ˆë‹¤ ë…ë¦½ì ì¸ context vector $\c_i$ë¥¼ ì‚¬ìš©í•œë‹¤ëŠ” ê²ƒì´ë‹¤.</p> <p>ê°ê°ì˜ c_iëŠ” encoderì´ ìƒì„±í•œ <code class="language-plaintext highlighter-rouge">annotation</code>ì˜ ìˆœì„œì— ë”°ë¼ ê³„ì‚°ëœë‹¤. ì´ë•Œ <code class="language-plaintext highlighter-rouge">annotation</code>ì€ ì „ì²´ input ìˆœì„œì— ëŒ€í•œ ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©° íŠ¹íˆ, ië²ˆì§¸ ë‹¨ì–´ ì£¼ë³€ì— ê°•í•˜ê²Œ ì´ˆì ì´ ë§ì¶”ì–´ì ¸ ìˆë‹¤. c_iëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ëœë‹¤.</p> <p>[ c_i = \sum_{j=1}^{T_x} \alpha_{ij} h_j. ]</p> <p>ì—¬ê¸°ì„œ ê°€ì¤‘í•© $\alpha_{ij}$ ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ëœë‹¤.</p> <p>[ \alpha_{ij} = \frac{\exp(e_{ij})}{\sum_{k=1}^{T_x} \exp(e_{ik})}, ]</p> <p>\alpha ëŠ” translation ë‹¨ì–´ë¥¼ ìƒì„±í•  ë•Œ ì–¼ë§ˆë‚˜ ê° contextì— attentioní•  ê±´ì§€ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤ê³  ìƒê°í•˜ë©´ ëœë‹¤. ì´ëŠ” alignment modelì´ë¼ê³  í•  ìˆ˜ ìˆëŠ”ë° ì´ëŠ” inputì˜ j ë²ˆì§¸ ë‹¨ì–´ì™€ outputì˜ i ë²ˆì§¸ ë‹¨ì–´ê°€ ì–¼ë§ˆë‚˜ ë§¤ì¹­ë˜ëŠ”ì§€ë¥¼ ì ìˆ˜ë§¤ê¸´ë‹¤. ì¦‰, decoderì˜ inputê³¼ outputì—ì„œ ì–´ë–¤ ë§¤ì¹­ì´ ì—°ê´€ì„±ì´ ë†’ì€ì§€ë¥¼ ê³„ì‚°í•œë‹¤ê³  ìƒê°í•˜ë©´ ëœë‹¤.</p> <p>ì¦‰, ì´ êµ¬ì¡°ë¥¼ í†µí•´ decoderì€ source sentenceì—ì„œ ì–´ëŠ ìœ„ì¹˜ì˜ ì–´ëŠ ë‹¨ì–´ì— ë” attentionì„ ê°€í•´ì„œ focusí•  ì§€ ì •í•  ìˆ˜ ìˆë‹¤.</p> <h3 id="3-2-encoder--bidirectional-rnn-for-annotating-sequence"> <a href="#3-2-encoder--bidirectional-rnn-for-annotating-sequence" class="anchor-heading" aria-labelledby="3-2-encoder--bidirectional-rnn-for-annotating-sequence"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3-2. Encoder : Bidirectional RNN for Annotating Sequence </h3> <p>encoderì—ì„œëŠ” ê¸°ì¡´ê³¼ëŠ” ë‹¬ë¦¬ ì–‘ë°©í–¥ìœ¼ë¡œ ì½ì–´ë‚˜ê°„ë‹¤.</p> <ul> <li>Forward RNNì˜ ê²½ìš° ìˆœì„œëŒ€ë¡œ ì½ì–´ë‚˜ê°€ë©° <code class="language-plaintext highlighter-rouge">forward hidden state</code> ë¥¼ ìƒì„±í•œë‹¤</li> <li>Backward RNNì˜ ê²½ìš° ê±°ê¾¸ë¡œ ì½ì–´ë‚˜ê°€ë©° <code class="language-plaintext highlighter-rouge">backward hidden state</code> ë¥¼ ìƒì„±í•œë‹¤</li> </ul> <h2 id="4-qualitative-analysis"> <a href="#4-qualitative-analysis" class="anchor-heading" aria-labelledby="4-qualitative-analysis"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 4. Qualitative Analysis </h2> <h3 id="4-1-alignment"> <a href="#4-1-alignment" class="anchor-heading" aria-labelledby="4-1-alignment"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 4-1. Alignment </h3> <p>weight Î±ij ë¥¼ í†µí•´ ìƒì„±ëœ ë²ˆì—­ë³¸ì˜ ë‹¨ì–´ë“¤ê³¼ source sentence ì‚¬ì´ì˜ soft-alignmentë¥¼ ì°¾ì„ ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤. ë˜í•œ (ì—¬ê¸°ì„œëŠ” ìƒëµë˜ì—ˆì§€ë§Œ) ì‹¤í—˜ì„ í†µí•´ source sentence ê·¸ ìì²´ë¥¼ ë²ˆì—­í•˜ëŠ” ì‘ì—…ì—ì„œ, ê° ë‹¨ì–´ê°€ ì–´ë–¤ ìœ„ì¹˜ì— ì†í•´ìˆëŠ”ì§€ë¥¼ íŒŒì•…í•˜ëŠ” ê²ƒì´ ë” ì¤‘ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ì•Œê²Œ ë˜ì—ˆë‹¤.</p> <p>ì—¬ê¸°ì„œ taskë¡œ ìˆ˜í–‰í•˜ê³  ìˆëŠ” ë²ˆì—­ ì‘ì—…ì€ English - French ì¸ë°, ì´ê±´ ë…¼ë¬¸ Figure 3ì—ë„ ë‚˜ì™€ìˆë“¯ì´ ë³´í†µ monotonicí•˜ë‹¤ (plotì„ ë³´ë©´ ì—°ê²°ë˜ëŠ” alignì´ ë³´í†µ ìš°í•˜í–¥í•˜ëŠ” ì¼ì§ì„  ëŒ€ê°ì„ ìœ¼ë¡œ í‘œì‹œë¨). ê·¸ì¹˜ë§Œ ì¼ë¶€ ë¶€ë¶„ì€ ì¡°ê¸ˆ ë‹¬ë¼ì§€ê¸°ê³  í•˜ê³ , í˜•ìš©ì‚¬ì™€ ëª…ì‚¬ê°™ì€ ê²½ìš° ë‘ ì–¸ì–´ì—ì„œ ë‹¤ë¥¸ ìˆœì„œë¡œ ì •ë ¬ë¨ì—ë„ ì˜ ë²ˆì—­ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.</p> <p>soft-alignmentë¥¼ í†µí•´ ë‹¨ì–´ë¥¼ ë‹¤ì–‘í•˜ê²Œ ë³´ë‹¤ ë³´ë‹ˆ ìœ ë™ì ìœ¼ë¡œ ë²ˆì—­í•  ìˆ˜ ìˆë‹¤ëŠ” ì ë„ ë“œëŸ¬ë‚¬ë‹¤.</p> <h3 id="4-2-long-sentences"> <a href="#4-2-long-sentences" class="anchor-heading" aria-labelledby="4-2-long-sentences"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 4-2. Long Sentences </h3> <p>RNN encoder-decoder ì€ ë¬¸ì¥ì´ ê¸¸ ë•Œ, ì¤‘ë°˜ê¹Œì§€ëŠ” ì˜ ë²ˆì—­í–ˆì§€ë§Œ í›„ë°˜ë¶€ë¶€í„° ì›ë³¸ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ë²—ì–´ë‚˜ê²Œ ë˜ì—ˆë‹¤.</p> <p>ê·¸ëŸ¬ë‚˜ ìƒˆë¡œ ë§Œë“  ëª¨ë¸ì˜ ê²½ìš° ì•„ì£¼ ì˜ ë²ˆì—­í•´ë‚¸ë‹¤.</p> <h2 id="5-model-architecture"> <a href="#5-model-architecture" class="anchor-heading" aria-labelledby="5-model-architecture"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5. Model Architecture </h2> <h3 id="5-1-recurrent-neural-network---gated-hidden-unit"> <a href="#5-1-recurrent-neural-network---gated-hidden-unit" class="anchor-heading" aria-labelledby="5-1-recurrent-neural-network---gated-hidden-unit"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5-1. Recurrent Neural Network - <strong>Gated Hidden Unit</strong> </h3> <p>RNN êµ¬ì¡°ì˜ activation function f ìë¦¬ì—ëŠ” <code class="language-plaintext highlighter-rouge">gated hidden unit</code>ì´ ë“¤ì–´ê°„ë‹¤. <code class="language-plaintext highlighter-rouge">gated hidden unit</code>ì€ ì´ì „ì— ì‚¬ìš©ë˜ì—ˆë˜ ì „í†µì ì¸ simple unit (ex. element-wise tanh) ê³¼ ë‹¤ë¥´ê³ , LSTMì—ì„œ ë‚˜ì™”ë˜ ê²ƒê³¼ ìœ ì‚¬í•˜ë‹¤.</p> <ul> <li>ëª¨ë¸ì´ long-term dependenciesë¥¼ ë” ì˜ í•™ìŠµí•  ìˆ˜ ìˆê²Œ ëœë‹¤</li> <li>ë„í•¨ìˆ˜ì˜ ê³±ì´ 1ì— ê°€ê¹Œìš´ computational pathë¥¼ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì—, vanishing effectì—ì„œ ì¢€ ë²—ì–´ë‚  ìˆ˜ ìˆë‹¤ (back-propagationì„ ì¢€ ë” ìˆ˜ì›”í•˜ê²Œ í•  ìˆ˜ ìˆë‹¤)</li> </ul> <p>ê·¸ë˜ì„œ ê·¸ëƒ¥ <code class="language-plaintext highlighter-rouge">gated hidden unit</code> ì„ ì“°ì§€ ì•Šê³  LSTM ì„ ê°–ë‹¤ê°€ ì¨ë„ ëœë‹¤.</p> <p>n ê°œì˜ <code class="language-plaintext highlighter-rouge">gated hidden unit</code> ì„ ì‚¬ìš©í•˜ëŠ” RNN decoderì—ì„œì˜ ìƒˆë¡œìš´ ìƒíƒœ ( s_i ) ëŠ” ì´ë ‡ê²Œ ê³„ì‚°ëœë‹¤.</p> <p>[ s_i = f(s_{i-1}, y_{i-1}, c_i) = (1 - z_i) \odot s_{i-1} + z_i \odot \tilde{s_i}, z_i = \sigma(W_z e(y_{i-1}) + U_z s_{i-1} + C_z c_i), r_i = \sigma(W_r e(y_{i-1}) + U_r s_{i-1} + C_r c_i) ]</p> <ul> <li>ìˆ˜ì‹ <ul> <li>$\odot$ : element-wise ê³±ì…ˆ</li> <li>$\sigma$ : logistic sigmoid function</li> <li>$\tanh$ : í•˜ì´í¼ë³¼ë¦­ íƒ„ì  íŠ¸ í•¨ìˆ˜ë¡œ í™œì„±í™” ê°’ ê³„ì‚°</li> </ul> </li> <li>Gates <ul> <li>$z_i$ : update gates - ê°ê°ì˜ hidden unitì´ ì´ì „ activationì„ ìœ ì§€í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.</li> <li>$r_i$ : reset gates - ì´ì „ ìƒíƒœì—ì„œ ì–´ë–¤ ì •ë³´ê°€ ì–¼ë§ˆë‚˜ resetë˜ì–´ì•¼ í•˜ëŠ”ì§€ë¥¼ ê²°ì •í•œë‹¤.</li> </ul> </li> <li>ê°€ì¤‘ì¹˜ í–‰ë ¬ <ul> <li>W : í˜„ì¬ ì…ë ¥ $\e(y_{i-1})$ ì™€ ê´€ë ¨ëœ ê°€ì¤‘ì¹˜ í–‰ë ¬ì´ë‹¤. Wë¥¼ í†µí•´ modelì˜ hidden ê³µê°„ì— íˆ¬ì˜í•œë‹¤.</li> <li>U : $\s_{i-1}$ ì™€ ê´€ë ¨ëœ ê°€ì¤‘ì¹˜ í–‰ë ¬ì´ë‹¤. Uë¥¼ í†µí•´ ì´ì „ hidden ìƒíƒœ ì •ë³´ë¥¼ í˜„ì¬ë¡œ ì „ë‹¬í•´ì„œ sequenceì˜ ë§¥ë½ì„ ìœ ì§€í•œë‹¤.</li> <li>C : $\c_i$ ì™€ ê´€ë ¨ëœ ê°€ì¤‘ì¹˜ í–‰ë ¬ì´ë‹¤.</li> </ul> </li> </ul> <p>decoderì˜ ê° ìŠ¤í…ì—ì„œ output í™•ë¥ ì´ ë‚˜ì˜¬ ê²ƒì´ê³ , softmaxë¥¼ í†µí•´ì„œ ê° ë‹¨ì–´ë§ˆë‹¤ output í™•ë¥ ì— ëŒ€í•´ ë¶„í¬ë¥¼ ë§Œë“ ë‹¤.</p> <p>ì¦‰, í™•ë¥ ì‹¸ì›€ì´ë‹¤. í•™ìŠµ ë°ì´í„°ì…‹ì—ì„œ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ë“¤ì˜ í™•ë¥  ë¶„í¬ë¥¼ í†µí•´ì„œ ê·¸ëŸ´ë“¯í•œ ë§ì„ ë§Œë“¤ì–´ë‚´ëŠ” ê²ƒì´ë‹¤.</p> <h3 id="5-2-alignment-model"> <a href="#5-2-alignment-model" class="anchor-heading" aria-labelledby="5-2-alignment-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5-2. Alignment Model </h3> <p>single-layer multilayer perceptron ì„ ì‚¬ìš©í•œë‹¤.</p> <p>[ a(s_{i-1}, h_j) = v^T \tanh(W_a s_{i-1} + U_a h_j) ]</p> <h3 id="5-3-encoder"> <a href="#5-3-encoder" class="anchor-heading" aria-labelledby="5-3-encoder"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5-3. Encoder </h3> <p>ê°€ì¥ ë¨¼ì € inputì¸ source sentenceì€ <code class="language-plaintext highlighter-rouge">1-of-K coded word vector</code> í˜•íƒœë¡œ ë“¤ì–´ê°„ë‹¤. outputì¸ translated sentenceë„ <code class="language-plaintext highlighter-rouge">1-of-K coded word vector</code> .</p> <p>[ x = (x_1, \ldots, x_{T_x}), x_i \in \mathbb{R}^{K_x} , y = (y_1, \ldots, y_{T_y}), y_i \in \mathbb{R}^{K_y} ]</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1-of-K coded word vectorê³¼ one-hot vectorì˜ ì°¨ì´

ì‚¬ì‹¤ìƒ ê°™ì€ ê°œë…ì´ë‹¤. ë¬¸ë§¥ì— ë”°ë¼ ì¡°ê¸ˆì”© ë‹¤ë¥´ê²Œ ì½í ìˆ˜ ìˆë‹¤. 

1-of-K coded word vector ì€ ê° ë‹¨ì–´ë¥¼ Kì°¨ì›ì˜ ë²¡í„°ë¡œ í‘œí˜„í•œë‹¤. 
í•´ë‹¹ ë‹¨ì–´ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ìœ„ì¹˜ì—ë§Œ 1ì´ ìˆê³  ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ ì±„ì›Œì§„ë‹¤.
ë‹¨ì–´ í•˜ë‚˜ë§Œ ì„ íƒëœë‹¤ëŠ” ì˜ë¯¸ê°€ ê°•í•¨. ìˆ˜í•™ì ìœ¼ë¡œ ë§ì´ ì‚¬ìš©ë˜ëŠ” ë“¯. 

One-hot vectorì€ ë‹¨ì–´, ë²”ì£¼í˜• ë°ì´í„° ë“±ì—ì„œ íŠ¹ì • í•­ëª©ì„ ê°€ë¦¬í‚¬ ë•Œ ì“´ë‹¤. 
ì¢€ ë” ë‹¨ìˆœí™”ëœ ê³³ì—ì„œ ì“°ì¼ ìˆ˜ ìˆì„ ê²ƒ. 
</code></pre></div></div> <p><strong>Forward State</strong></p> <p>Bidirectional RNNì—ì„œ forward stateëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ëœë‹¤. w [</p> <p>\overrightarrow{h_i} = \begin{cases} (1 - \overrightarrow{z_i}) \odot \overrightarrow{h_{i-1}} + \overrightarrow{z_i} \odot \tilde{\overrightarrow{h_i}}, &amp; \text{if } i &gt; 0 <br /> 0, &amp; \text{if } i = 0 \end{cases}</p> <p>\overrightarrow{h_i} = (1 - \overrightarrow{z_i}) \odot \overrightarrow{h_{i-1}} + \overrightarrow{z_i} \odot \tilde{\overrightarrow{h_i}},</p> <p>\tilde{\overrightarrow{h_i}} = \tanh(\overrightarrow{W} E x_i + \overrightarrow{U} [\overrightarrow{r_i} \odot \overrightarrow{h_{i-1}}]),</p> <p>\overrightarrow{z_i} = \sigma(\overrightarrow{W_z} E x_i + \overrightarrow{U_z} \overrightarrow{h_{i-1}}),</p> <p>\overrightarrow{r_i} = \sigma(\overrightarrow{W_r} E x_i + \overrightarrow{U_r} \overrightarrow{h_{i-1}}),</p> <p>]</p> <p>update gate $\overrightarrow{z_i}$ ë¥¼ í†µí•´ ê¸°ì¡´ ì •ë³´ì™€ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì ì ˆíˆ í˜¼í•©í•´ì„œ ê³¼ê±° ì •ë³´ë¥¼ ìœ ì§€í•˜ë©´ì„œë„ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì…ë ¥ë°›ì„ ìˆ˜ ìˆë‹¤.</p> <ul> <li>$(1 - \overrightarrow{z_i}) \circ \overrightarrow{h_{i-1}}$ ë¥¼ í†µí•´ ê¸°ì¡´ ì •ë³´ë¥¼ ì–¼ë§ˆë‚˜ ìœ ì§€í•  ì§€ ê²°ì •í•œë‹¤. (ìƒˆë¡œìš´ ì •ë³´ì™€ì˜ ìƒì‡„ë¥¼ í†µí•´ ê¸°ì¡´ ì •ë³´ë¥¼ ë¶€ë¶„ì ìœ¼ë¡œ ìœ ì§€)</li> <li>$\overrightarrow{z_i} \circ \widetilde{\overrightarrow{h_i}}$ ë¥¼ í†µí•´ í˜„ì¬ ì…ë ¥ê³¼ ë¬¸ë§¥ì— ê¸°ë°˜í•´ì„œ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì–¼ë§ˆë‚˜ ë°˜ì˜í•  ì§€ ê²°ì •í•œë‹¤.</li> </ul> <p>ì´ˆê¸° ì…ë ¥ ë‹¨ì–´ë¼ë©´ ê¸°ì¡´ ì •ë³´ê°€ ê±°ì˜ ì—†ìœ¼ë¯€ë¡œ $\overrightarrow{z_i}$ ê°€ í¬ê³  ìƒˆë¡œìš´ ì •ë³´ë“¤ì´ ê±°ì˜ ë‹¤ ë°˜ì˜ë  ê²ƒì´ë‹¤. ë§Œì•½ ê¸´ ë¬¸ì¥ì—ì„œ ì´ë¯¸ contextê°€ ì¢€ ë°˜ì˜ëœ ì‹œì ì´ë¼ë©´, $\overrightarrow{z_i}$ ê°€ ì‘ê³  ê¸°ì¡´ ë¬¸ë§¥ì´ ë” ë§ì´ ìœ ì§€ë  ê²ƒì´ë‹¤.</p> <p><strong>Backward State</strong></p> <p>backward stateë„ ìœ ì‚¬í•˜ê²Œ ê³„ì‚°ëœë‹¤. fowardì™€ backward RNNì€ ë‹¨ì–´ ì„ë² ë”©ì„ ê³µìœ í•˜ê¸´ í•˜ì§€ë§Œ <strong>ê°€ì¤‘ì¹˜ í–‰ë ¬ì€ ê³µìœ í•˜ì§€ ì•ŠëŠ”ë‹¤</strong>.</p> <h3 id="5-4-decoder"> <a href="#5-4-decoder" class="anchor-heading" aria-labelledby="5-4-decoder"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5-4. Decoder </h3> <p>ë³¸ë¬¸ì— ê±°ì˜ ë‹¤ ì–¸ê¸‰ëœ ë‚´ìš©ì´ë¼, ê°„ë‹¨í•˜ê²Œ ì§šê³  ë„˜ì–´ê°€ì.</p> <p>[ \tilde{s_i} = \tanh(W E y_{i-1} + U [r_i \circ s_{i-1}] + C c_i), z_i = \sigma(W_z E y_{i-1} + U_z s_{i-1} + C_z c_i), r_i = \sigma(W_r E y_{i-1} + U_r s_{i-1} + C_r c_i) ]</p> <p>context vectorì€ ì´ë ‡ê²Œ ê³„ì‚°ëœë‹¤.</p> <p>[ c_i = \sum_{j=1}^{T_x} \alpha_{ij} h_j ]</p> <h2 id="6-ì •ë¦¬"> <a href="#6-ì •ë¦¬" class="anchor-heading" aria-labelledby="6-ì •ë¦¬"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 6. ì •ë¦¬ </h2> <p>ì •ë¦¬ë¥¼ í•´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.</p> <ul> <li>Attentionì´ë€ <ul> <li>hidden layerì˜ ì •ë³´ë¥¼ ì €ì¥í•´ì„œ ë§¥ë½ ìƒ ì–¼ë§ˆë‚˜ ì €ì¥í•˜ê³  ë²„ë¦´ ê²ƒì¸ì§€ íŒë‹¨í•´ì„œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆë„ë¡ ë§Œë“œëŠ” êµ¬ì¡°.</li> <li>ì–´ë–¤ ë¶€ë¶„ì„ ë‚´ê°€ ì¢€ ë” ì£¼ì˜í•´ì„œ ë´ì•¼ í•˜ëŠ”ê°€? ì— ë‹µí•˜ëŠ” ê³¼ì •.</li> </ul> </li> <li>Attentionì´ ìˆ˜í–‰ë˜ëŠ” ê³¼ì • <ul> <li>alignment score ê³„ì‚° : í˜„ decoder ìƒíƒœì™€ annotation h ë¥¼ ê¸°ë°˜ìœ¼ë¡œ â€˜ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€â€™ë¥¼ ì¸¡ì •í•˜ëŠ” alignment ê³„ì‚° (FFNN ì´ìš©)</li> <li>attention ê°€ì¤‘ì¹˜ ê³„ì‚°</li> <li>context vector ê³„ì‚°</li> <li>decoder ì—…ë°ì´íŠ¸</li> <li>ì¶œë ¥ ë‹¨ì–´ ìƒì„±</li> </ul> </li> </ul><hr /> <h3> <a href="#6-ì •ë¦¬" class="anchor-heading" aria-labelledby="6-ì •ë¦¬"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> ğŸ”— Related Posts in Paper </h3> <ul> <li><a href="/paper/2025/01/06/Seq2Seq.html">[Seq2Seq] Sequence to Sequence Learning with Neural Networks (2014)</a> (2025-01-06)</li> <li><a href="/paper/2025/01/05/LSTM.html">[LSTM] Long Short Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling (2014)</a> (2025-01-05)</li> <li><a href="/paper/2025/01/04/Word2Vec.html">[Word2Vec] Efficient Estimation of Word Representations in Vector Space (2013)</a> (2025-01-04)</li> <li><a href="/paper/2025/01/03/RNN.html">[RNN] Recurrent neural network based language model (2010)</a> (2025-01-03)</li> </ul> <nav class="post-nav"> <a class="prev" href="/paper/2025/01/06/Seq2Seq.html">â† [Seq2Seq] Sequence to Sequence Learning with Neural Networks (2014)</a> <a class="next" href="/nlp/2025/03/02/batchapi.html">ì¼ë°˜ APIì™€ Batch API ì‚¬ìš©í•˜ê¸° â†’</a> </nav> </main> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
