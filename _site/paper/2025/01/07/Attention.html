<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav ul li a { background-image: none; } </style> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015) | Rachel Docs</title> <meta name="generator" content="Jekyll v4.3.4" /> <meta property="og:title" content="[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015)" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="1. Intro" /> <meta property="og:description" content="1. Intro" /> <link rel="canonical" href="http://localhost:4000/paper/2025/01/07/Attention.html" /> <meta property="og:url" content="http://localhost:4000/paper/2025/01/07/Attention.html" /> <meta property="og:site_name" content="Rachel Docs" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2025-01-07T00:00:00+09:00" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015)" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-01-07T00:00:00+09:00","datePublished":"2025-01-07T00:00:00+09:00","description":"1. Intro","headline":"[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/paper/2025/01/07/Attention.html"},"url":"http://localhost:4000/paper/2025/01/07/Attention.html"}</script> <!-- End Jekyll SEO tag --> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> Rachel Docs </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/posts" class="nav-list-link">Posts by Category</a></li><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Rachel Docs" aria-label="Search Rachel Docs" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://github.com/just-the-docs/just-the-docs-template" class="site-button" > Template Repository </a> </li> </ul> </nav> </div> <div class="main-content-wrap"> <div id="main-content" class="main-content"> <main> <h1>[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015)</h1> <h2 id="1-intro"> <a href="#1-intro" class="anchor-heading" aria-labelledby="1-intro"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1. Intro </h2> <p>Neural Machine Translation 은 기계번역에서 새롭게 등장하는 접근이다.</p> <p>기존에 있었던 Traditional Phrase-based translation system의 경우 sub component들이 있고 각각 tune되어야 했지만, 이 neural machine translation은 1개의 거대한 신경망 구조이다 (확실히 학습 시 효율적일 것)</p> <p>일반적으로 기계번역 모델이라고 하면 encoder-decoder 형식이고, 각 언어가 encoder, decoder을 각각 차지한다. encoder이 기존 문장을 fixed-length 벡터로 읽어들인 후, decoder이 그에 대한 번역을 도출한다. 여기서 <strong>fixed-length 벡터로 읽어들인다는 점</strong>이, 긴 문장을 대하기 어렵다는 점에서 한계점이다. 특히 훈련 코퍼스에서 긴 문장이 있을 시 제대로 학습이 안될 것이다.</p> <p>그래서 align과 translate를 동시에 학습하는 encoder-decoder model을 제시한다.</p> <ul> <li>translation으로 단어를 생성해서 제시함</li> <li>가장 관련된 정보가 집중되어 있는 <code class="language-plaintext highlighter-rouge">source sentence</code>에서의 <code class="language-plaintext highlighter-rouge">set of positions</code> 를 탐색함</li> <li><code class="language-plaintext highlighter-rouge">source position</code>과 이전에 생성된 모든 target words 를 기반으로 target word를 예측함</li> </ul> <p>특히 가장 주목할만한 특징은 fixed-length 구조가 아니라는 것이다. 즉, 그 길이에 맞춰서 자를 필요가 없어졌으니 긴 문장에 더욱 강력한 성능을 뽐낼 것이다.</p> <h2 id="2-background"> <a href="#2-background" class="anchor-heading" aria-labelledby="2-background"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2. Background </h2> <p>확률적 관점에서 보면 기계번역은, source sentence x에 대해서 target sentence의 conditional probability y를 최대화하는 것이다. 이를 위해 신경망 구조를 활용하는 것이 대두되었고, 특히 RNN을 두개 사용하는 방식으로 구현된다.</p> <ul> <li>한 RNN은 다양한 길이의 source sentence를 fixed-length 벡터로 encode하는 데에 사용</li> <li>나머지 RNN은 다시 다양한 길이의 target sentence로 decode하는 데에 사용</li> </ul> <p>즉, 정리하면 <code class="language-plaintext highlighter-rouge">variable-length → fixed length → variable-length</code> 로 가는 것이다.</p> <h3 id="2-1-rnn-encoder-decoder"> <a href="#2-1-rnn-encoder-decoder" class="anchor-heading" aria-labelledby="2-1-rnn-encoder-decoder"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2-1. RNN Encoder-Decoder </h3> <p>encoder이 input sentence를 읽는다 ($\x = (x_1, \ldots, x_{T_x})$ 를 c^2로 변환) . hidden layer은 일반적으로 $\h_t = f(x_t, h_{t-1})$ 와 같은 형태로 구성된다. 그리고</p> <p>[ c = q({h_1, \ldots, h_{T_x}}) ]</p> <p>를 통해 context vector c를 계산한다.</p> <p>decoder은 c와 이전에 만들어진 단어들 ( {y_1, \ldots, y_{t’-1}} ) 을 고려하여 다음 단어인 y를 예측한다.</p> <p>[ p(y) = \prod_{t=1}^{T} p(y_t | {y_1, \ldots, y_{t-1}}, c), ]</p> <p>[ p(y_t | {y_1, \ldots, y_{t-1}}, c) = g(y_{t-1}, s_t, c), ]</p> <p>여기서 함수 g는 확률을 끌어내기 위한 비선형함수가 될 것읻다.</p> <h2 id="3-learning-to-align-and-translate"> <a href="#3-learning-to-align-and-translate" class="anchor-heading" aria-labelledby="3-learning-to-align-and-translate"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3. Learning to Align and Translate </h2> <p>align과 translate를 어떻게 동시에 학습할 수 있을까? 이를 위해 새로운 구조를 도입한다.</p> <ul> <li>encoder : bidrectional RNN</li> <li>decoder : source sentence를 탐색하는 구조를 모방</li> </ul> <h3 id="3-1-decoder"> <a href="#3-1-decoder" class="anchor-heading" aria-labelledby="3-1-decoder"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3-1. Decoder </h3> <p>기존 RNN Encoder-Decoder 모델에서는</p> <p>[ p(y) = \prod_{t=1}^{T} p(y_t | {y_1, \ldots, y_{t-1}}, c), ]</p> <p>로 정의했던 p(y)를 이제는</p> <p>[ p(y_i | y_1, \ldots, y_{i-1}, x) = g(y_{i-1}, s_i, c_i), ]</p> <p>로 정의한다. 가장 큰 차이점은, 각 단어 $\y_i$마다 독립적인 context vector $\c_i$를 사용한다는 것이다.</p> <p>각각의 c_i는 encoder이 생성한 <code class="language-plaintext highlighter-rouge">annotation</code>의 순서에 따라 계산된다. 이때 <code class="language-plaintext highlighter-rouge">annotation</code>은 전체 input 순서에 대한 정보를 가지고 있으며 특히, i번째 단어 주변에 강하게 초점이 맞추어져 있다. c_i는 다음과 같이 계산된다.</p> <p>[ c_i = \sum_{j=1}^{T_x} \alpha_{ij} h_j. ]</p> <p>여기서 가중합 $\alpha_{ij}$ 는 다음과 같이 계산된다.</p> <p>[ \alpha_{ij} = \frac{\exp(e_{ij})}{\sum_{k=1}^{T_x} \exp(e_{ik})}, ]</p> <p>\alpha 는 translation 단어를 생성할 때 얼마나 각 context에 attention할 건지를 나타낸다고 생각하면 된다. 이는 alignment model이라고 할 수 있는데 이는 input의 j 번째 단어와 output의 i 번째 단어가 얼마나 매칭되는지를 점수매긴다. 즉, decoder의 input과 output에서 어떤 매칭이 연관성이 높은지를 계산한다고 생각하면 된다.</p> <p>즉, 이 구조를 통해 decoder은 source sentence에서 어느 위치의 어느 단어에 더 attention을 가해서 focus할 지 정할 수 있다.</p> <h3 id="3-2-encoder--bidirectional-rnn-for-annotating-sequence"> <a href="#3-2-encoder--bidirectional-rnn-for-annotating-sequence" class="anchor-heading" aria-labelledby="3-2-encoder--bidirectional-rnn-for-annotating-sequence"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3-2. Encoder : Bidirectional RNN for Annotating Sequence </h3> <p>encoder에서는 기존과는 달리 양방향으로 읽어나간다.</p> <ul> <li>Forward RNN의 경우 순서대로 읽어나가며 <code class="language-plaintext highlighter-rouge">forward hidden state</code> 를 생성한다</li> <li>Backward RNN의 경우 거꾸로 읽어나가며 <code class="language-plaintext highlighter-rouge">backward hidden state</code> 를 생성한다</li> </ul> <h2 id="4-qualitative-analysis"> <a href="#4-qualitative-analysis" class="anchor-heading" aria-labelledby="4-qualitative-analysis"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 4. Qualitative Analysis </h2> <h3 id="4-1-alignment"> <a href="#4-1-alignment" class="anchor-heading" aria-labelledby="4-1-alignment"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 4-1. Alignment </h3> <p>weight αij 를 통해 생성된 번역본의 단어들과 source sentence 사이의 soft-alignment를 찾을 수 있게 되었다. 또한 (여기서는 생략되었지만) 실험을 통해 source sentence 그 자체를 번역하는 작업에서, 각 단어가 어떤 위치에 속해있는지를 파악하는 것이 더 중요하다는 것을 알게 되었다.</p> <p>여기서 task로 수행하고 있는 번역 작업은 English - French 인데, 이건 논문 Figure 3에도 나와있듯이 보통 monotonic하다 (plot을 보면 연결되는 align이 보통 우하향하는 일직선 대각선으로 표시됨). 그치만 일부 부분은 조금 달라지기고 하고, 형용사와 명사같은 경우 두 언어에서 다른 순서로 정렬됨에도 잘 번역되는 것을 볼 수 있다.</p> <p>soft-alignment를 통해 단어를 다양하게 보다 보니 유동적으로 번역할 수 있다는 점도 드러났다.</p> <h3 id="4-2-long-sentences"> <a href="#4-2-long-sentences" class="anchor-heading" aria-labelledby="4-2-long-sentences"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 4-2. Long Sentences </h3> <p>RNN encoder-decoder 은 문장이 길 때, 중반까지는 잘 번역했지만 후반부부터 원본 문장의 의미를 벗어나게 되었다.</p> <p>그러나 새로 만든 모델의 경우 아주 잘 번역해낸다.</p> <h2 id="5-model-architecture"> <a href="#5-model-architecture" class="anchor-heading" aria-labelledby="5-model-architecture"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5. Model Architecture </h2> <h3 id="5-1-recurrent-neural-network---gated-hidden-unit"> <a href="#5-1-recurrent-neural-network---gated-hidden-unit" class="anchor-heading" aria-labelledby="5-1-recurrent-neural-network---gated-hidden-unit"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5-1. Recurrent Neural Network - <strong>Gated Hidden Unit</strong> </h3> <p>RNN 구조의 activation function f 자리에는 <code class="language-plaintext highlighter-rouge">gated hidden unit</code>이 들어간다. <code class="language-plaintext highlighter-rouge">gated hidden unit</code>은 이전에 사용되었던 전통적인 simple unit (ex. element-wise tanh) 과 다르고, LSTM에서 나왔던 것과 유사하다.</p> <ul> <li>모델이 long-term dependencies를 더 잘 학습할 수 있게 된다</li> <li>도함수의 곱이 1에 가까운 computational path를 가지고 있기 때문에, vanishing effect에서 좀 벗어날 수 있다 (back-propagation을 좀 더 수월하게 할 수 있다)</li> </ul> <p>그래서 그냥 <code class="language-plaintext highlighter-rouge">gated hidden unit</code> 을 쓰지 않고 LSTM 을 갖다가 써도 된다.</p> <p>n 개의 <code class="language-plaintext highlighter-rouge">gated hidden unit</code> 을 사용하는 RNN decoder에서의 새로운 상태 ( s_i ) 는 이렇게 계산된다.</p> <p>[ s_i = f(s_{i-1}, y_{i-1}, c_i) = (1 - z_i) \odot s_{i-1} + z_i \odot \tilde{s_i}, z_i = \sigma(W_z e(y_{i-1}) + U_z s_{i-1} + C_z c_i), r_i = \sigma(W_r e(y_{i-1}) + U_r s_{i-1} + C_r c_i) ]</p> <ul> <li>수식 <ul> <li>$\odot$ : element-wise 곱셈</li> <li>$\sigma$ : logistic sigmoid function</li> <li>$\tanh$ : 하이퍼볼릭 탄젠트 함수로 활성화 값 계산</li> </ul> </li> <li>Gates <ul> <li>$z_i$ : update gates - 각각의 hidden unit이 이전 activation을 유지할 수 있도록 한다.</li> <li>$r_i$ : reset gates - 이전 상태에서 어떤 정보가 얼마나 reset되어야 하는지를 결정한다.</li> </ul> </li> <li>가중치 행렬 <ul> <li>W : 현재 입력 $\e(y_{i-1})$ 와 관련된 가중치 행렬이다. W를 통해 model의 hidden 공간에 투영한다.</li> <li>U : $\s_{i-1}$ 와 관련된 가중치 행렬이다. U를 통해 이전 hidden 상태 정보를 현재로 전달해서 sequence의 맥락을 유지한다.</li> <li>C : $\c_i$ 와 관련된 가중치 행렬이다.</li> </ul> </li> </ul> <p>decoder의 각 스텝에서 output 확률이 나올 것이고, softmax를 통해서 각 단어마다 output 확률에 대해 분포를 만든다.</p> <p>즉, 확률싸움이다. 학습 데이터셋에서 등장하는 단어들의 확률 분포를 통해서 그럴듯한 말을 만들어내는 것이다.</p> <h3 id="5-2-alignment-model"> <a href="#5-2-alignment-model" class="anchor-heading" aria-labelledby="5-2-alignment-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5-2. Alignment Model </h3> <p>single-layer multilayer perceptron 을 사용한다.</p> <p>[ a(s_{i-1}, h_j) = v^T \tanh(W_a s_{i-1} + U_a h_j) ]</p> <h3 id="5-3-encoder"> <a href="#5-3-encoder" class="anchor-heading" aria-labelledby="5-3-encoder"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5-3. Encoder </h3> <p>가장 먼저 input인 source sentence은 <code class="language-plaintext highlighter-rouge">1-of-K coded word vector</code> 형태로 들어간다. output인 translated sentence도 <code class="language-plaintext highlighter-rouge">1-of-K coded word vector</code> .</p> <p>[ x = (x_1, \ldots, x_{T_x}), x_i \in \mathbb{R}^{K_x} , y = (y_1, \ldots, y_{T_y}), y_i \in \mathbb{R}^{K_y} ]</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1-of-K coded word vector과 one-hot vector의 차이

사실상 같은 개념이다. 문맥에 따라 조금씩 다르게 읽힐 수 있다. 

1-of-K coded word vector 은 각 단어를 K차원의 벡터로 표현한다. 
해당 단어를 나타내는 위치에만 1이 있고 나머지는 0으로 채워진다.
단어 하나만 선택된다는 의미가 강함. 수학적으로 많이 사용되는 듯. 

One-hot vector은 단어, 범주형 데이터 등에서 특정 항목을 가리킬 때 쓴다. 
좀 더 단순화된 곳에서 쓰일 수 있을 것. 
</code></pre></div></div> <p><strong>Forward State</strong></p> <p>Bidirectional RNN에서 forward state는 다음과 같이 계산된다. w [</p> <p>\overrightarrow{h_i} = \begin{cases} (1 - \overrightarrow{z_i}) \odot \overrightarrow{h_{i-1}} + \overrightarrow{z_i} \odot \tilde{\overrightarrow{h_i}}, &amp; \text{if } i &gt; 0 <br /> 0, &amp; \text{if } i = 0 \end{cases}</p> <p>\overrightarrow{h_i} = (1 - \overrightarrow{z_i}) \odot \overrightarrow{h_{i-1}} + \overrightarrow{z_i} \odot \tilde{\overrightarrow{h_i}},</p> <p>\tilde{\overrightarrow{h_i}} = \tanh(\overrightarrow{W} E x_i + \overrightarrow{U} [\overrightarrow{r_i} \odot \overrightarrow{h_{i-1}}]),</p> <p>\overrightarrow{z_i} = \sigma(\overrightarrow{W_z} E x_i + \overrightarrow{U_z} \overrightarrow{h_{i-1}}),</p> <p>\overrightarrow{r_i} = \sigma(\overrightarrow{W_r} E x_i + \overrightarrow{U_r} \overrightarrow{h_{i-1}}),</p> <p>]</p> <p>update gate $\overrightarrow{z_i}$ 를 통해 기존 정보와 새로운 정보를 적절히 혼합해서 과거 정보를 유지하면서도 새로운 정보를 입력받을 수 있다.</p> <ul> <li>$(1 - \overrightarrow{z_i}) \circ \overrightarrow{h_{i-1}}$ 를 통해 기존 정보를 얼마나 유지할 지 결정한다. (새로운 정보와의 상쇄를 통해 기존 정보를 부분적으로 유지)</li> <li>$\overrightarrow{z_i} \circ \widetilde{\overrightarrow{h_i}}$ 를 통해 현재 입력과 문맥에 기반해서 새로운 정보를 얼마나 반영할 지 결정한다.</li> </ul> <p>초기 입력 단어라면 기존 정보가 거의 없으므로 $\overrightarrow{z_i}$ 가 크고 새로운 정보들이 거의 다 반영될 것이다. 만약 긴 문장에서 이미 context가 좀 반영된 시점이라면, $\overrightarrow{z_i}$ 가 작고 기존 문맥이 더 많이 유지될 것이다.</p> <p><strong>Backward State</strong></p> <p>backward state도 유사하게 계산된다. foward와 backward RNN은 단어 임베딩을 공유하긴 하지만 <strong>가중치 행렬은 공유하지 않는다</strong>.</p> <h3 id="5-4-decoder"> <a href="#5-4-decoder" class="anchor-heading" aria-labelledby="5-4-decoder"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5-4. Decoder </h3> <p>본문에 거의 다 언급된 내용이라, 간단하게 짚고 넘어가자.</p> <p>[ \tilde{s_i} = \tanh(W E y_{i-1} + U [r_i \circ s_{i-1}] + C c_i), z_i = \sigma(W_z E y_{i-1} + U_z s_{i-1} + C_z c_i), r_i = \sigma(W_r E y_{i-1} + U_r s_{i-1} + C_r c_i) ]</p> <p>context vector은 이렇게 계산된다.</p> <p>[ c_i = \sum_{j=1}^{T_x} \alpha_{ij} h_j ]</p> <h2 id="6-정리"> <a href="#6-정리" class="anchor-heading" aria-labelledby="6-정리"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 6. 정리 </h2> <p>정리를 해보면 다음과 같다.</p> <ul> <li>Attention이란 <ul> <li>hidden layer의 정보를 저장해서 맥락 상 얼마나 저장하고 버릴 것인지 판단해서 다음 단어를 예측할 수 있도록 만드는 구조.</li> <li>어떤 부분을 내가 좀 더 주의해서 봐야 하는가? 에 답하는 과정.</li> </ul> </li> <li>Attention이 수행되는 과정 <ul> <li>alignment score 계산 : 현 decoder 상태와 annotation h 를 기반으로 ‘얼마나 중요한지’를 측정하는 alignment 계산 (FFNN 이용)</li> <li>attention 가중치 계산</li> <li>context vector 계산</li> <li>decoder 업데이트</li> <li>출력 단어 생성</li> </ul> </li> </ul><hr /> <h3> <a href="#6-정리" class="anchor-heading" aria-labelledby="6-정리"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 🔗 Related Posts in Paper </h3> <ul> <li><a href="/paper/2025/01/06/Seq2Seq.html">[Seq2Seq] Sequence to Sequence Learning with Neural Networks (2014)</a> (2025-01-06)</li> <li><a href="/paper/2025/01/05/LSTM.html">[LSTM] Long Short Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling (2014)</a> (2025-01-05)</li> <li><a href="/paper/2025/01/04/Word2Vec.html">[Word2Vec] Efficient Estimation of Word Representations in Vector Space (2013)</a> (2025-01-04)</li> <li><a href="/paper/2025/01/03/RNN.html">[RNN] Recurrent neural network based language model (2010)</a> (2025-01-03)</li> </ul> <nav class="post-nav"> <a class="prev" href="/paper/2025/01/06/Seq2Seq.html">← [Seq2Seq] Sequence to Sequence Learning with Neural Networks (2014)</a> <a class="next" href="/nlp/2025/03/02/batchapi.html">일반 API와 Batch API 사용하기 →</a> </nav> </main> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
