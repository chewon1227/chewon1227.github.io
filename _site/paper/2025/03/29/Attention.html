<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav ul li a { background-image: none; } .site-nav > ul.nav-category-list > li > button svg { transform: rotate(-90deg); } .site-nav > ul.nav-category-list > li.nav-list-item > ul.nav-list { display: block; } </style> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015) | Rachel Docs</title> <meta name="generator" content="Jekyll v4.3.4" /> <meta property="og:title" content="[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015)" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="1. Intro" /> <meta property="og:description" content="1. Intro" /> <link rel="canonical" href="http://localhost:4000/paper/2025/03/29/Attention.html" /> <meta property="og:url" content="http://localhost:4000/paper/2025/03/29/Attention.html" /> <meta property="og:site_name" content="Rachel Docs" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2025-03-29T00:00:00+09:00" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015)" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-03-29T00:00:00+09:00","datePublished":"2025-03-29T00:00:00+09:00","description":"1. Intro","headline":"[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/paper/2025/03/29/Attention.html"},"url":"http://localhost:4000/paper/2025/03/29/Attention.html"}</script> <!-- End Jekyll SEO tag --> <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"> </script> <!-- KaTeX for math rendering --> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"> <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body, { delimiters: [ {left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false} ] });"> </script> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> Rachel Docs </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"> <li class="nav-list-item"> <a href="/" class="nav-list-link">Home</a> </li> <li class="nav-list-item"> <a href="/categories/dl.html" class="nav-list-link">DL</a> </li> <li class="nav-list-item"> <a href="/categories/nlp.html" class="nav-list-link">NLP</a> </li> <li class="nav-list-item"> <a href="/categories/eda.html" class="nav-list-link">EDA</a> </li> <li class="nav-list-item"> <a href="/categories/paper.html" class="nav-list-link">PAPER</a> </li> </ul> </nav> <nav aria-label="Categories" id="category-nav" class="site-nav"> <ul class="nav-list nav-category-list"> <li class="nav-list-item"> <button class="nav-list-expander btn-reset" aria-label="Toggle category DL" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <div class="nav-category">DL</div> <ul class="nav-list"> <li class="nav-list-item"> <a href="/dl/tensorflow-04/" class="nav-list-link"> TensorFlowë¥¼ ì´ìš©í•œ Deep Learning 04 </a> </li> <li class="nav-list-item"> <a href="/dl/tensorflow-03/" class="nav-list-link"> TensorFlowë¥¼ ì´ìš©í•œ Deep Learning 03 </a> </li> <li class="nav-list-item"> <a href="/dl/tensorflow-02/" class="nav-list-link"> TensorFlowë¥¼ ì´ìš©í•œ Deep Learning 02 </a> </li> <li class="nav-list-item"> <a href="/dl/tensorflow-01/" class="nav-list-link"> TensorFlowë¥¼ ì´ìš©í•œ Deep Learning 01 </a> </li> </ul> </li> </ul> <ul class="nav-list nav-category-list"> <li class="nav-list-item"> <button class="nav-list-expander btn-reset" aria-label="Toggle category EDA" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <div class="nav-category">EDA</div> <ul class="nav-list"> <li class="nav-list-item"> <a href="/eda/bus-eda-01/" class="nav-list-link"> ì„œìš¸ì‹œ ë²„ìŠ¤ ë…¸ì„  ì •ë¥˜ì¥ ìŠ¹í•˜ì°¨ ë¶„ì„ - 01 </a> </li> </ul> </li> </ul> <ul class="nav-list nav-category-list"> <li class="nav-list-item"> <button class="nav-list-expander btn-reset" aria-label="Toggle category NLP" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <div class="nav-category">NLP</div> <ul class="nav-list"> <li class="nav-list-item"> <a href="/nlp/react/" class="nav-list-link"> ReAct: Synergizing Reasoning and Acting in Language Models </a> </li> <li class="nav-list-item"> <a href="/nlp/gpt1/" class="nav-list-link"> [GPT-1] Improving Language Understanding by Generative Pre-Training(2018) </a> </li> <li class="nav-list-item"> <a href="/nlp/batchapi/" class="nav-list-link"> ì¼ë°˜ APIì™€ Batch API ì‚¬ìš©í•˜ê¸° </a> </li> <li class="nav-list-item"> <a href="/nlp/colab-finetune/" class="nav-list-link"> Colabìœ¼ë¡œ íŒŒì¸íŠœë‹(Fine-Tuning)í•˜ê¸° </a> </li> <li class="nav-list-item"> <a href="/nlp/colab-prompting/" class="nav-list-link"> Colabìœ¼ë¡œ í”„ë¡¬í”„íŒ…(Prompting)í•˜ê¸° </a> </li> </ul> </li> </ul> <ul class="nav-list nav-category-list"> <li class="nav-list-item"> <button class="nav-list-expander btn-reset" aria-label="Toggle category Paper" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button> <div class="nav-category">Paper</div> <ul class="nav-list"> <li class="nav-list-item"> <a href="/paper/2025/03/29/Attention.html" class="nav-list-link"> [Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015) </a> </li> <li class="nav-list-item"> <a href="/nlp/seq2seq/" class="nav-list-link"> Sequence-to-Sequence Models </a> </li> <li class="nav-list-item"> <a href="/paper/2025/02/24/LSTM.html" class="nav-list-link"> [LSTM] Long Short Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling (2014) </a> </li> <li class="nav-list-item"> <a href="/paper/2025/02/14/Word2Vec.html" class="nav-list-link"> [Word2Vec] Efficient Estimation of Word Representations in Vector Space (2013) </a> </li> <li class="nav-list-item"> <a href="/paper/2025/02/05/RNN.html" class="nav-list-link"> [RNN] Recurrent neural network based language model (2010) </a> </li> </ul> </li> </ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Rachel Docs" aria-label="Search Rachel Docs" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://github.com/just-the-docs/just-the-docs-template" class="site-button" > Template Repository </a> </li> </ul> </nav> </div> <div class="main-content-wrap"> <div id="main-content" class="main-content"> <main> <h1>[Attention] Neural Machine Translation by Jointly Learning to Align and Translate (2015)</h1> <h2 id="1-intro"> <a href="#1-intro" class="anchor-heading" aria-labelledby="1-intro"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1. Intro </h2> <p><strong>Neural Machine Translation</strong>ì€ ê¸°ê³„ë²ˆì—­ì—ì„œ ìƒˆë¡­ê²Œ ë“±ì¥í•˜ëŠ” ì ‘ê·¼ì´ë‹¤.</p> <p>ê¸°ì¡´ì— ìˆì—ˆë˜ Traditional Phrase-based translation systemì˜ ê²½ìš° sub componentë“¤ì´ ìˆê³  ê°ê° tuneë˜ì–´ì•¼ í–ˆì§€ë§Œ, ì´ neural machine translationì€ 1ê°œì˜ ê±°ëŒ€í•œ ì‹ ê²½ë§ êµ¬ì¡°ì´ë‹¤ (í™•ì‹¤íˆ í•™ìŠµ ì‹œ íš¨ìœ¨ì ì¼ ê²ƒ)</p> <p>ì¼ë°˜ì ìœ¼ë¡œ ê¸°ê³„ë²ˆì—­ ëª¨ë¸ì´ë¼ê³  í•˜ë©´ encoder-decoder í˜•ì‹ì´ê³ , ê° ì–¸ì–´ê°€ encoder, decoderì„ ê°ê° ì°¨ì§€í•œë‹¤. encoderì´ ê¸°ì¡´ ë¬¸ì¥ì„ fixed-length ë²¡í„°ë¡œ ì½ì–´ë“¤ì¸ í›„, decoderì´ ê·¸ì— ëŒ€í•œ ë²ˆì—­ì„ ë„ì¶œí•œë‹¤. ì—¬ê¸°ì„œ fixed-length ë²¡í„°ë¡œ ì½ì–´ë“¤ì¸ë‹¤ëŠ” ì ì´, ê¸´ ë¬¸ì¥ì„ ëŒ€í•˜ê¸° ì–´ë µë‹¤ëŠ” ì ì—ì„œ í•œê³„ì ì´ë‹¤. íŠ¹íˆ í›ˆë ¨ ì½”í¼ìŠ¤ì—ì„œ ê¸´ ë¬¸ì¥ì´ ìˆì„ ì‹œ ì œëŒ€ë¡œ í•™ìŠµì´ ì•ˆë  ê²ƒì´ë‹¤.</p> <p>ê·¸ë˜ì„œ alignê³¼ translateë¥¼ ë™ì‹œì— í•™ìŠµí•˜ëŠ” encoder-decoder modelì„ ì œì‹œí•œë‹¤. â€¢ translationìœ¼ë¡œ ë‹¨ì–´ë¥¼ ìƒì„±í•´ì„œ ì œì‹œí•¨ â€¢ ê°€ì¥ ê´€ë ¨ëœ ì •ë³´ê°€ ì§‘ì¤‘ë˜ì–´ ìˆëŠ” source sentenceì—ì„œì˜ set of positions ë¥¼ íƒìƒ‰í•¨ â€¢ source positionê³¼ ì´ì „ì— ìƒì„±ëœ ëª¨ë“  target words ë¥¼ ê¸°ë°˜ìœ¼ë¡œ target wordë¥¼ ì˜ˆì¸¡í•¨</p> <p>íŠ¹íˆ ê°€ì¥ ì£¼ëª©í• ë§Œí•œ íŠ¹ì§•ì€ fixed-length êµ¬ì¡°ê°€ ì•„ë‹ˆë¼ëŠ” ê²ƒì´ë‹¤. ì¦‰, ê·¸ ê¸¸ì´ì— ë§ì¶°ì„œ ìë¥¼ í•„ìš”ê°€ ì—†ì–´ì¡Œìœ¼ë‹ˆ ê¸´ ë¬¸ì¥ì— ë”ìš± ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë½ë‚¼ ê²ƒì´ë‹¤.</p><hr /> <h2 id="2-background"> <a href="#2-background" class="anchor-heading" aria-labelledby="2-background"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2. Background </h2> <p>í™•ë¥ ì  ê´€ì ì—ì„œ ë³´ë©´ ê¸°ê³„ë²ˆì—­ì€, source sentence $x$ì— ëŒ€í•´ì„œ target sentenceì˜ conditional probability $y$ë¥¼ ìµœëŒ€í™”í•˜ëŠ” ê²ƒì´ë‹¤. ì´ë¥¼ ìœ„í•´ ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ í™œìš©í•˜ëŠ” ê²ƒì´ ëŒ€ë‘ë˜ì—ˆê³ , íŠ¹íˆ RNNì„ ë‘ ê°œ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ëœë‹¤. â€¢ í•œ RNNì€ ë‹¤ì–‘í•œ ê¸¸ì´ì˜ source sentenceë¥¼ fixed-length ë²¡í„°ë¡œ encodeí•˜ëŠ” ë°ì— ì‚¬ìš© â€¢ ë‚˜ë¨¸ì§€ RNNì€ ë‹¤ì‹œ ë‹¤ì–‘í•œ ê¸¸ì´ì˜ target sentenceë¡œ decodeí•˜ëŠ” ë°ì— ì‚¬ìš©</p> <p>ì¦‰, ì •ë¦¬í•˜ë©´ variable-length â†’ fixed length â†’ variable-length ë¡œ ê°€ëŠ” ê²ƒì´ë‹¤.</p> <h3 id="2-1-rnn-encoder-decoder"> <a href="#2-1-rnn-encoder-decoder" class="anchor-heading" aria-labelledby="2-1-rnn-encoder-decoder"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2-1. RNN Encoder-Decoder </h3> <p>encoderì´ input sentenceë¥¼ ì½ëŠ”ë‹¤ - $x = (x_1, \ldots, x_{T_x})$ ë¥¼ $c^2$ë¡œ ë³€í™˜í•´ì„œ! hidden layerì€ ì¼ë°˜ì ìœ¼ë¡œ $h_t = f(x_t, h_{t-1})$ ì™€ ê°™ì€ í˜•íƒœë¡œ êµ¬ì„±ëœë‹¤. ê·¸ë¦¬ê³ </p> \[c = q({h_1, \ldots, h_{T_x}})\] <p>ë¥¼ í†µí•´ context vector $c$ë¥¼ ê³„ì‚°í•œë‹¤.</p> <p>decoderì€ $c$ì™€ ì´ì „ì— ë§Œë“¤ì–´ì§„ ë‹¨ì–´ë“¤ ${y_1, \ldots, y_{tâ€™-1}}$ ì„ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒ ë‹¨ì–´ì¸ $y$ë¥¼ ì˜ˆì¸¡í•œë‹¤.</p> \[p(y) = \prod_{t=1}^{T} p(y_t \mid {y_1, \ldots, y_{t-1}}, c),\] \[p(y_t \mid {y_1, \ldots, y_{t-1}}, c) = g(y_{t-1}, s_t, c),\] <p>ì—¬ê¸°ì„œ í•¨ìˆ˜ $g$ëŠ” í™•ë¥ ì„ ëŒì–´ë‚´ê¸° ìœ„í•œ ë¹„ì„ í˜• í•¨ìˆ˜ê°€ ë  ê²ƒì´ë‹¤.</p><hr /> <h2 id="3-learning-to-align-and-translate"> <a href="#3-learning-to-align-and-translate" class="anchor-heading" aria-labelledby="3-learning-to-align-and-translate"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3. Learning to Align and Translate </h2> <p>alignê³¼ translateë¥¼ ì–´ë–»ê²Œ ë™ì‹œì— í•™ìŠµí•  ìˆ˜ ìˆì„ê¹Œ? ì´ë¥¼ ìœ„í•´ ìƒˆë¡œìš´ êµ¬ì¡°ë¥¼ ë„ì…í•œë‹¤. â€¢ encoder : bidirectional RNN â€¢ decoder : source sentenceë¥¼ íƒìƒ‰í•˜ëŠ” êµ¬ì¡°ë¥¼ ëª¨ë°©</p> <h3 id="3-1-decoder"> <a href="#3-1-decoder" class="anchor-heading" aria-labelledby="3-1-decoder"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3-1. Decoder </h3> <p>ê¸°ì¡´ RNN Encoder-Decoder ëª¨ë¸ì—ì„œëŠ”</p> \[p(y) = \prod_{t=1}^{T} p(y_t \mid {y_1, \ldots, y_{t-1}}, c),\] <p>ë¡œ ì •ì˜í–ˆë˜ $p(y)$ë¥¼ ì´ì œëŠ”</p> \[p(y_i \mid y_1, \ldots, y_{i-1}, x) = g(y_{i-1}, s_i, c_i),\] <p>ë¡œ ì •ì˜í•œë‹¤. ê°€ì¥ í° ì°¨ì´ì ì€, ê° ë‹¨ì–´ $y_i$ë§ˆë‹¤ ë…ë¦½ì ì¸ context vector $c_i$ë¥¼ ì‚¬ìš©í•œë‹¤ëŠ” ê²ƒì´ë‹¤.</p> <p>ê°ê°ì˜ $c_i$ëŠ” encoderì´ ìƒì„±í•œ annotationì˜ ìˆœì„œì— ë”°ë¼ ê³„ì‚°ëœë‹¤. ì´ë•Œ annotationì€ ì „ì²´ input ìˆœì„œì— ëŒ€í•œ ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©° íŠ¹íˆ, $i$ë²ˆì§¸ ë‹¨ì–´ ì£¼ë³€ì— ê°•í•˜ê²Œ ì´ˆì ì´ ë§ì¶”ì–´ì ¸ ìˆë‹¤. $c_i$ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ëœë‹¤.</p> \[c_i = \sum_{j=1}^{T_x} \alpha_{ij} h_j\] <p>ì—¬ê¸°ì„œ ê°€ì¤‘í•© $\alpha_{ij}$ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ëœë‹¤.</p> \[\alpha_{ij} = \frac{\exp(e_{ij})}{\sum_{k=1}^{T_x} \exp(e_{ik})}\] <p>$\alpha$ëŠ” translation ë‹¨ì–´ë¥¼ ìƒì„±í•  ë•Œ ì–¼ë§ˆë‚˜ ê° contextì— attentioní•  ê±´ì§€ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. ì´ëŠ” alignment modelì´ë¼ê³  í•  ìˆ˜ ìˆëŠ”ë° inputì˜ $j$ ë²ˆì§¸ ë‹¨ì–´ì™€ outputì˜ $i$ ë²ˆì§¸ ë‹¨ì–´ê°€ ì–¼ë§ˆë‚˜ ë§¤ì¹­ë˜ëŠ”ì§€ë¥¼ ì ìˆ˜ë§¤ê¸´ë‹¤.</p> <p>ì¦‰, decoderëŠ” source sentenceì—ì„œ ì–´ëŠ ìœ„ì¹˜ì˜ ë‹¨ì–´ì— ë” attentionì„ ì¤„ì§€ë¥¼ ê²°ì •í•  ìˆ˜ ìˆë‹¤.</p> <h3 id="3-2-encoder--bidirectional-rnn-for-annotating-sequence"> <a href="#3-2-encoder--bidirectional-rnn-for-annotating-sequence" class="anchor-heading" aria-labelledby="3-2-encoder--bidirectional-rnn-for-annotating-sequence"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3-2. Encoder : Bidirectional RNN for Annotating Sequence </h3> <p>encoderì—ì„œëŠ” ê¸°ì¡´ê³¼ëŠ” ë‹¬ë¦¬ ì–‘ë°©í–¥ìœ¼ë¡œ ì½ì–´ë‚˜ê°„ë‹¤. â€¢ Forward RNNì˜ ê²½ìš° ìˆœì„œëŒ€ë¡œ ì½ì–´ë‚˜ê°€ë©° forward hidden stateë¥¼ ìƒì„±í•œë‹¤ â€¢ Backward RNNì˜ ê²½ìš° ê±°ê¾¸ë¡œ ì½ì–´ë‚˜ê°€ë©° backward hidden stateë¥¼ ìƒì„±í•œë‹¤</p><hr /> <h2 id="4-qualitative-analysis"> <a href="#4-qualitative-analysis" class="anchor-heading" aria-labelledby="4-qualitative-analysis"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 4. Qualitative Analysis </h2> <h3 id="4-1-alignment"> <a href="#4-1-alignment" class="anchor-heading" aria-labelledby="4-1-alignment"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 4-1. Alignment </h3> <p>weight $\alpha_{ij}$ ë¥¼ í†µí•´ soft-alignmentë¥¼ ì°¾ì„ ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤.</p> <h3 id="4-2-long-sentences"> <a href="#4-2-long-sentences" class="anchor-heading" aria-labelledby="4-2-long-sentences"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 4-2. Long Sentences </h3> <p>ê¸°ì¡´ RNNì€ ë¬¸ì¥ì´ ê¸¸ ê²½ìš° í›„ë°˜ë¶€ ë²ˆì—­ì´ íë ¤ì¡Œì§€ë§Œ, ìƒˆ ëª¨ë¸ì€ ì˜ í•´ë‚¸ë‹¤.</p><hr /> <h2 id="5-model-architecture"> <a href="#5-model-architecture" class="anchor-heading" aria-labelledby="5-model-architecture"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5. Model Architecture </h2> <h3 id="5-1-recurrent-neural-network---gated-hidden-unit"> <a href="#5-1-recurrent-neural-network---gated-hidden-unit" class="anchor-heading" aria-labelledby="5-1-recurrent-neural-network---gated-hidden-unit"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5-1. Recurrent Neural Network - Gated Hidden Unit </h3> <p>activation function $f$ ìë¦¬ì—ëŠ” gated hidden unitì´ ë“¤ì–´ê°„ë‹¤. LSTMê³¼ ìœ ì‚¬í•œ êµ¬ì¡°ë¡œ long-term dependencyë¥¼ ì˜ í•™ìŠµí•œë‹¤.</p> \[s_i = (1 - z_i) \odot s_{i-1} + z_i \odot \tilde{s_i},\] \[z_i = \sigma(W_z e(y_{i-1}) + U_z s_{i-1} + C_z c_i), \quad r_i = \sigma(W_r e(y_{i-1}) + U_r s_{i-1} + C_r c_i)\] <h3 id="5-2-alignment-model"> <a href="#5-2-alignment-model" class="anchor-heading" aria-labelledby="5-2-alignment-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5-2. Alignment Model </h3> \[a(s_{i-1}, h_j) = v^T \tanh(W_a s_{i-1} + U_a h_j)\] <h3 id="5-3-encoder"> <a href="#5-3-encoder" class="anchor-heading" aria-labelledby="5-3-encoder"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5-3. Encoder </h3> <p>ì…ë ¥ $x = (x_1, \ldots, x_{T_x}), \quad x_i \in \mathbb{R}^{K_x}$ ì¶œë ¥ $y = (y_1, \ldots, y_{T_y}), \quad y_i \in \mathbb{R}^{K_y}$</p> <p>Forward state (bidirectional RNN)</p> \[\overrightarrow{h_i} = (1 - \overrightarrow{z_i}) \odot \overrightarrow{h_{i-1}} + \overrightarrow{z_i} \odot \tilde{\overrightarrow{h_i}},\] \[\tilde{\overrightarrow{h_i}} = \tanh(\overrightarrow{W} E x_i + \overrightarrow{U} [\overrightarrow{r_i} \odot \overrightarrow{h_{i-1}}]),\] \[\overrightarrow{z_i} = \sigma(\overrightarrow{W_z} E x_i + \overrightarrow{U_z} \overrightarrow{h_{i-1}}),\] \[\overrightarrow{r_i} = \sigma(\overrightarrow{W_r} E x_i + \overrightarrow{U_r} \overrightarrow{h_{i-1}})\] <h3 id="5-4-decoder"> <a href="#5-4-decoder" class="anchor-heading" aria-labelledby="5-4-decoder"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5-4. Decoder </h3> \[\tilde{s_i} = \tanh(W E y_{i-1} + U [r_i \odot s_{i-1}] + C c_i),\] \[z_i = \sigma(W_z E y_{i-1} + U_z s_{i-1} + C_z c_i), \quad r_i = \sigma(W_r E y_{i-1} + U_r s_{i-1} + C_r c_i)\] \[c_i = \sum_{j=1}^{T_x} \alpha_{ij} h_j\] <h2 id="6-ì •ë¦¬"> <a href="#6-ì •ë¦¬" class="anchor-heading" aria-labelledby="6-ì •ë¦¬"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 6. ì •ë¦¬ </h2> <div class="callout"> â€¢ Attentionì´ë€ â†’ hidden layer ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡ ì‹œ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì§‘ì¤‘í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ â€¢ ìˆ˜í–‰ ê³¼ì • â†’ alignment ê³„ì‚° â†’ attention weight ê³„ì‚° â†’ context vector ìƒì„± â†’ decoder ì—…ë°ì´íŠ¸ </div><hr /> <h3> <a href="#6-ì •ë¦¬" class="anchor-heading" aria-labelledby="6-ì •ë¦¬"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> ğŸ”— Related Posts in Paper </h3> <ul> <li><a href="/nlp/seq2seq/">Sequence-to-Sequence Models</a> (2025-03-15)</li> <li><a href="/paper/2025/02/24/LSTM.html">[LSTM] Long Short Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling (2014)</a> (2025-02-24)</li> <li><a href="/paper/2025/02/14/Word2Vec.html">[Word2Vec] Efficient Estimation of Word Representations in Vector Space (2013)</a> (2025-02-14)</li> <li><a href="/paper/2025/02/05/RNN.html">[RNN] Recurrent neural network based language model (2010)</a> (2025-02-05)</li> </ul> <nav class="post-nav"> <a class="prev" href="/nlp/seq2seq/">â† Sequence-to-Sequence Models</a> <a class="next" href="/nlp/batchapi/">ì¼ë°˜ APIì™€ Batch API ì‚¬ìš©í•˜ê¸° â†’</a> </nav> </main> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
